{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch-mnist-GAN.ipynb のコピー のコピー",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satoruk-icepp/mlhep2019_2_phase/blob/master/analysis/pytorch_mnist_conditional_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKYoeYeyQAD3",
        "colab_type": "code",
        "outputId": "585dcdaf-2602-4415-cdb5-21a3cea1f991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "! [ ! -z \"$COLAB_GPU\" ] && pip install skorch comet_ml"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: skorch in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: comet_ml in /usr/local/lib/python3.6/dist-packages (2.0.4)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.16.4)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (4.28.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.8.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.21.2)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.12.0)\n",
            "Requirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.6.0)\n",
            "Requirement already satisfied: netifaces>=0.10.7 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.10.9)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.21.0)\n",
            "Requirement already satisfied: websocket-client>=0.55.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.56.0)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (7.352.0)\n",
            "Requirement already satisfied: everett[ini]>=1.0.1; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.0.2)\n",
            "Requirement already satisfied: comet-git-pure>=0.19.11 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.19.11)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (0.13.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (3.0.4)\n",
            "Requirement already satisfied: configobj; extra == \"ini\" in /usr/local/lib/python3.6/dist-packages (from everett[ini]>=1.0.1; python_version >= \"3.0\"->comet_ml) (5.0.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SmYMA7VQCAj",
        "colab_type": "code",
        "outputId": "c4f85a9e-ea7b-4ee7-9d3a-e94fa3187c84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile .comet.config\n",
        "[comet]\n",
        "api_key=mIel5ZAPOioTs0Cij75dSSQXs\n",
        "logging_file = /tmp/comet.log\n",
        "logging_file_level = info"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting .comet.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1RZ8iaWP8DH",
        "colab_type": "code",
        "outputId": "87b55b71-a4a1-4ef2-d991-51917adf5b9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from comet_ml import Experiment\n",
        "experiment = Experiment(project_name=\"BayesMNISTGAN\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/satoruk-icepp/bayesmnistgan/9a50a43438ee4561ab52ce3bccaa298b\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6IWfDz7NmzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prerequisites\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVTZw9A1ZTJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot(a, num_classes):\n",
        "    return np.squeeze(np.eye(num_classes)[a.reshape(-1)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkDJiBTf8RZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_prior_std=1\n",
        "disc_prior_std=1\n",
        "bs = 100\n",
        "z_dim = 100\n",
        "lr = 0.0002 \n",
        "alpha=0.002\n",
        "n_epoch = 200\n",
        "Nresblock = 5\n",
        "params={'batch_size': bs,\n",
        "#         'data_size':N,\n",
        "        'epochs': n_epoch,\n",
        "#         'energyscale': EnergyDepositScale,\n",
        "        'noise_dim': z_dim,\n",
        "        'learning_rate':lr,\n",
        "        'alpha':alpha,\n",
        "        'gen_prior_std':gen_prior_std,\n",
        "        'disc_prior_std':disc_prior_std,\n",
        "#         'gnoise_alpha':gnoise_alpha,\n",
        "#         'Ngen':Ngen,\n",
        "#         'Ndisc':Ndisc,\n",
        "#         'PXscale':PXscale,\n",
        "#         'PYscale':PYscale,\n",
        "#         'PZscale':PZscale,\n",
        "#         'XPosscale':XPosscale,\n",
        "#         'YPosscale':YPosscale,\n",
        "        'Nresblock':Nresblock\n",
        "}\n",
        "experiment.log_parameters(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpV3CPvANmzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# MNIST Dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
        "    transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transform, download=False)\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hau0ljR1CMOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReducedConv(nn.Module):\n",
        "    def __init__(self,input_size,output_size, input_dim, output_dim,kernel_size):\n",
        "        super(ReducedConv, self).__init__()\n",
        "        scale = float(output_dim+kernel_size-3)/float(input_dim)\n",
        "        self.ups = nn.Upsample(scale_factor = scale,mode = 'bilinear',align_corners=False )\n",
        "        self.ref = nn.ReflectionPad2d(1)\n",
        "        self.conv = nn.Conv2d(input_size,output_size,kernel_size)\n",
        "    def forward(self,x):\n",
        "        return self.conv(self.ref(self.ups(x)))\n",
        "#         return self.ref(self.ups(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JwnK8WnCOQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self,input_size):\n",
        "        super(ResidualBlock, self).__init__()        \n",
        "        self.conv1 = nn.Conv2d(input_size,input_size,3,padding=1)\n",
        "    def forward(self,xraw):\n",
        "        x = F.leaky_relu(self.conv1(xraw))\n",
        "        x = F.leaky_relu(self.conv1(x)+xraw)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C07A7qgNmzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, g_input_dim, g_output_dim):\n",
        "        super(Generator, self).__init__()       \n",
        "        self.output_dim = g_output_dim\n",
        "        self.fc1 = nn.Linear(g_input_dim+10, 256)\n",
        "        self.bn_fc1 = nn.BatchNorm1d(self.fc1.out_features)        \n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n",
        "        self.bn_fc2 = nn.BatchNorm1d(self.fc2.out_features)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n",
        "        self.bn_fc3 = nn.BatchNorm1d(self.fc3.out_features)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, 16*(g_output_dim-4)**2)\n",
        "        self.trconv1 = nn.ConvTranspose2d(16, 16, 3)\n",
        "        self.trconv2 = nn.ConvTranspose2d(16, 1, 3)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.resblock = ResidualBlock(16)\n",
        "        self.redconv1 = ReducedConv(16,16,g_output_dim,g_output_dim,3)\n",
        "        self.redconv2 = ReducedConv(16,1,g_output_dim,g_output_dim,3)        \n",
        "    \n",
        "    # forward method\n",
        "    def forward(self, x,label):\n",
        "        x = torch.cat([x,label],dim=1)\n",
        "        x = F.leaky_relu(self.bn_fc1(self.fc1(x)), 0.2)\n",
        "        x = F.leaky_relu(self.bn_fc2(self.fc2(x)), 0.2)\n",
        "        x = F.leaky_relu(self.bn_fc3(self.fc3(x)), 0.2)\n",
        "        x = F.leaky_relu(self.fc4(x), 0.2)\n",
        "#         x = x.view(-1,16,self.output_dim,self.output_dim)\n",
        "        x = x.view(-1,16,self.output_dim-4,self.output_dim-4)\n",
        "        x= F.leaky_relu(self.bn1(self.trconv1(x)))\n",
        "        for i in range(Nresblock):\n",
        "            x = F.leaky_relu(self.resblock(x),0.2)        \n",
        "        x= self.trconv2(x)\n",
        "\n",
        "#         x = F.leaky_relu(self.redconv1(x) ,0.2)\n",
        "#         x = self.redconv2(x)\n",
        "#         x = self.resblock(x)\n",
        "        x = torch.tanh(x)\n",
        "        return x\n",
        "    \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, d_input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        kernel_size =3\n",
        "        self.input_dim = d_input_dim\n",
        "        self.conv1 = nn.Conv2d(1,16,kernel_size)\n",
        "        self.conv2 = nn.Conv2d(self.conv1.out_channels,self.conv1.out_channels,kernel_size)\n",
        "        nlayer=0\n",
        "#         self.fc1 = nn.Linear(self.conv1.out_channels*(d_input_dim-(kernel_size-1)*1)**2+10, 1024)\n",
        "        self.fc1 = nn.Linear(d_input_dim**2+10, 1024)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, 1)\n",
        "    \n",
        "    # forward method\n",
        "    def forward(self, x,label):\n",
        "#         print(x.shape,label.shape)\n",
        "#         x = x.view(-1,self.fc1.in_features)\n",
        "#         x = F.leaky_relu(self.conv1(x),0.2)\n",
        "#         x = F.dropout(x, 0.3)    \n",
        "#         x = F.leaky_relu(self.conv2(x),0.2)\n",
        "        x = x.view(-1,self.fc1.in_features-10)\n",
        "        label = label.view(-1,10)    \n",
        "        x = torch.cat([x,label],dim=1)\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        return torch.sigmoid(self.fc4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YEMdIlHNmzN",
        "colab_type": "code",
        "outputId": "a4734c2e-f3f0-4f01-f7c9-37bc46cfd335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# build network\n",
        "\n",
        "dataset_size = train_dataset.train_data.size(0)\n",
        "mnist_dim = train_dataset.train_data.size(1) * train_dataset.train_data.size(2)\n",
        "mnist_dimx = train_dataset.train_data.size(1)\n",
        "mnist_dimy = train_dataset.train_data.size(2)\n",
        "\n",
        "G = Generator(g_input_dim = z_dim, g_output_dim = mnist_dimx).to(device)\n",
        "D = Discriminator(mnist_dimx).to(device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSoTY6t2NmzP",
        "colab_type": "code",
        "outputId": "a4066958-ee88-4972-d739-c764496fd737",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "G"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (fc1): Linear(in_features=110, out_features=256, bias=True)\n",
              "  (bn_fc1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
              "  (bn_fc2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc3): Linear(in_features=512, out_features=1024, bias=True)\n",
              "  (bn_fc3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc4): Linear(in_features=1024, out_features=9216, bias=True)\n",
              "  (trconv1): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (trconv2): ConvTranspose2d(16, 1, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (resblock): ResidualBlock(\n",
              "    (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  )\n",
              "  (redconv1): ReducedConv(\n",
              "    (ups): Upsample(scale_factor=1.0, mode=bilinear)\n",
              "    (ref): ReflectionPad2d((1, 1, 1, 1))\n",
              "    (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  )\n",
              "  (redconv2): ReducedConv(\n",
              "    (ups): Upsample(scale_factor=1.0, mode=bilinear)\n",
              "    (ref): ReflectionPad2d((1, 1, 1, 1))\n",
              "    (conv): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkty5XlWNmzS",
        "colab_type": "code",
        "outputId": "abdf2992-9c56-4a59-c9a3-a30f2c1a04b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "D"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=794, out_features=1024, bias=True)\n",
              "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6rgxkWyTkTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NoiseLoss(torch.nn.Module):\n",
        "  # need the scale for noise standard deviation\n",
        "  # scale = noise  std\n",
        "    def __init__(self, params, noise_std, observed=None):\n",
        "        super(NoiseLoss, self).__init__()\n",
        "        self.observed = observed\n",
        "        self.noise_std = noise_std\n",
        "\n",
        "    def forward(self, params,  observed=None):\n",
        "    # scale should be sqrt(2*alpha/eta)\n",
        "    # where eta is the learning rate and alpha is the strength of drag term\n",
        "        if observed is None:\n",
        "            observed = self.observed\n",
        "\n",
        "#         assert scale is not None, \"Please provide scale\"\n",
        "        noise_loss = 0.0\n",
        "        for var in params:\n",
        "            # This is scale * z^T*v\n",
        "            # The derivative wrt v will become scale*z\n",
        "#             _noise = noise.normal_(0.,self.noise_std)\n",
        "            _noise = self.noise_std*torch.randn(1)\n",
        "            noise_loss += torch.sum(Variable(_noise)*var)\n",
        "        noise_loss /= observed\n",
        "        return noise_loss\n",
        "\n",
        "class PriorLoss(torch.nn.Module):\n",
        "  # negative log Gaussian prior\n",
        "    def __init__(self, prior_std=1., observed=None):\n",
        "        super(PriorLoss, self).__init__()\n",
        "        self.observed = observed\n",
        "        self.prior_std = prior_std\n",
        "\n",
        "    def forward(self, params, observed=None):\n",
        "        if observed is None:\n",
        "            observed = self.observed\n",
        "        prior_loss = 0.0\n",
        "        for var in params:\n",
        "            prior_loss += torch.sum(var*var/(self.prior_std*self.prior_std))\n",
        "        prior_loss /= observed\n",
        "        return prior_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHLA-9hoNmzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss\n",
        "criterion = nn.BCELoss() \n",
        "\n",
        "# optimizer\n",
        "\n",
        "G_optimizer = optim.Adam(G.parameters(), lr = lr)\n",
        "D_optimizer = optim.Adam(D.parameters(), lr = lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7a7qhQjTtc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "gprior_criterion = PriorLoss(prior_std=gen_prior_std, observed=dataset_size)\n",
        "gnoise_criterion = NoiseLoss(params=G.parameters(), noise_std=math.sqrt(2 * alpha * lr), observed=dataset_size)\n",
        "dprior_criterion = PriorLoss(prior_std=disc_prior_std, observed=dataset_size)\n",
        "dnoise_criterion = NoiseLoss(params=D.parameters(), noise_std=math.sqrt(2 * alpha * lr), observed=dataset_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR7jjNqXNmzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def D_train(x,y):\n",
        "    #=======================Train the discriminator=======================#\n",
        "    D.zero_grad()\n",
        "    \n",
        "    # train discriminator on real\n",
        "    x_real,y_label, y_real = x.view(-1,1, mnist_dimx,mnist_dimx), torch.FloatTensor(one_hot(y,10)),torch.ones(bs, 1)\n",
        "    x_real,y_label, y_real = Variable(x_real.to(device)), Variable(y_label.to(device)),Variable(y_real.to(device))\n",
        "\n",
        "    D_output = D(x_real,y_label)\n",
        "    D_real_loss = criterion(D_output, y_real)\n",
        "    D_real_score = D_output\n",
        "\n",
        "    # train discriminator on facke\n",
        "    z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "    x_fake, y_fake = G(z,y_label), Variable(torch.zeros(bs, 1).to(device))\n",
        "\n",
        "    D_output = D(x_fake,y_label)\n",
        "    D_fake_loss = criterion(D_output, y_fake)\n",
        "    D_fake_score = D_output\n",
        "    # Bayesian Loss\n",
        "    D_prior_loss = dprior_criterion(D.parameters())\n",
        "    D_noise_loss = dnoise_criterion(D.parameters())\n",
        "\n",
        "    # gradient backprop & optimize ONLY D's parameters\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "    D_loss += D_prior_loss + D_noise_loss\n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "        \n",
        "    return  D_loss.data.item(), D_real_loss.data.item(),D_fake_loss.data.item(),D_prior_loss.data.item(),D_noise_loss.data.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cwsPhcdNmzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def G_train(x,y):\n",
        "    #=======================Train the generator=======================#\n",
        "    G.zero_grad()\n",
        "\n",
        "    z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "    y_label = Variable(torch.FloatTensor(one_hot(y,10)).to(device))\n",
        "    y_real  = Variable(torch.ones(bs, 1).to(device))\n",
        "#     print(y_label.shape)\n",
        "    G_output = G(z,y_label)\n",
        "    D_output = D(G_output,y_label)\n",
        "    G_real_loss = criterion(D_output, y_real)\n",
        "    G_prior_loss = gprior_criterion(G.parameters())\n",
        "    G_noise_loss = gnoise_criterion(G.parameters())\n",
        "    G_loss=G_real_loss+G_prior_loss+G_noise_loss\n",
        "\n",
        "    # gradient backprop & optimize ONLY G's parameters\n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "        \n",
        "    return G_loss.data.item(),G_real_loss.data.item(),G_prior_loss.data.item(),G_noise_loss.data.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "hK-vO2liNmza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "ibatch = 0\n",
        "with experiment.train():\n",
        "    for epoch in range(1, n_epoch+1):           \n",
        "        D_losses, G_losses = [], []\n",
        "        for batch_idx, (x, y) in enumerate(train_loader):\n",
        "#             print(x,y.shape)\n",
        "            D_loss,D_real_loss,D_fake_loss,D_prior_loss,D_noise_loss = D_train(x,y)\n",
        "            G_loss,G_real_loss,G_prior_loss,G_noise_loss = G_train(x,y)\n",
        "            D_losses.append(D_loss)\n",
        "            G_losses.append(G_loss)\n",
        "            y_label = Variable(torch.FloatTensor(one_hot(y,10)).to(device))\n",
        "#             print(y_label.shape)\n",
        "            experiment.log_metric(\"d_loss\", D_loss,step=ibatch)\n",
        "            experiment.log_metric(\"g_loss\", G_loss,step=ibatch)\n",
        "            experiment.log_metric(\"d_real_loss\", D_real_loss,step=ibatch)\n",
        "            experiment.log_metric(\"d_fake_loss\", D_fake_loss,step=ibatch)\n",
        "            experiment.log_metric(\"d_prior_loss\", D_prior_loss,step=ibatch)            \n",
        "            experiment.log_metric(\"d_noise_loss\", D_noise_loss,step=ibatch)            \n",
        "            experiment.log_metric(\"g_real_loss\", G_real_loss,step=ibatch)\n",
        "            experiment.log_metric(\"g_prior_loss\", G_prior_loss,step=ibatch)\n",
        "            experiment.log_metric(\"g_noise_loss\", G_noise_loss,step=ibatch)\n",
        "            if ibatch%10==0:\n",
        "                clear_output()\n",
        "                plt.figure(figsize=(30,12))\n",
        "                grid = plt.GridSpec(2, 5, wspace=0.4, hspace=0.3)\n",
        "                label = torch.LongTensor([i for i in range(10)])\n",
        "                label =  Variable(torch.FloatTensor(one_hot(label,10)).to(device))                \n",
        "                z = Variable(torch.randn(10, z_dim).to(device))                \n",
        "                generated=G(z,label)\n",
        "                generated=generated.view(generated.size(0), 1, 28, 28)\n",
        "                for i in range(10):\n",
        "                    plt.subplot(grid[i//5,i%5])\n",
        "                    plt.imshow(generated[i][0].detach())\n",
        "                    plt.title(\"%d\"%(i))\n",
        "                experiment.log_figure(figure=plt)\n",
        "            ibatch += 1\n",
        "\n",
        "        print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % (\n",
        "                (epoch), n_epoch, torch.mean(torch.FloatTensor(D_losses)), torch.mean(torch.FloatTensor(G_losses))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdD7P9f0Nmzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    test_z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "    generated = G(test_z)\n",
        "\n",
        "    save_image(generated.view(generated.size(0), 1, 28, 28), './samples/sample_' + '.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMQNe4XkNmze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}