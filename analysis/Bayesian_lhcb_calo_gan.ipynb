{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bayesian_lhcb_calo_gan.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satoruk-icepp/mlhep2019_2_phase/blob/master/analysis/Bayesian_lhcb_calo_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud8PAMb2mDK9",
        "colab_type": "code",
        "outputId": "3c932997-8911-48a2-e20f-1dc151a4c339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "! wget https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/calogan_metrics.py\n",
        "! wget https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/prd_score.py\n",
        "! wget https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/score.py\n",
        "! wget https://github.com/SchattenGenie/mlhep2019_2_phase/raw/master/analysis/embedder.tp\n",
        "! wget https://github.com/SchattenGenie/mlhep2019_2_phase/raw/master/analysis/generator.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-14 20:26:08--  https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/calogan_metrics.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4115 (4.0K) [text/plain]\n",
            "Saving to: ‘calogan_metrics.py.12’\n",
            "\n",
            "\rcalogan_metrics.py.   0%[                    ]       0  --.-KB/s               \rcalogan_metrics.py. 100%[===================>]   4.02K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-07-14 20:26:08 (113 MB/s) - ‘calogan_metrics.py.12’ saved [4115/4115]\n",
            "\n",
            "--2019-07-14 20:26:10--  https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/prd_score.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12426 (12K) [text/plain]\n",
            "Saving to: ‘prd_score.py.12’\n",
            "\n",
            "prd_score.py.12     100%[===================>]  12.13K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-07-14 20:26:10 (161 MB/s) - ‘prd_score.py.12’ saved [12426/12426]\n",
            "\n",
            "--2019-07-14 20:26:11--  https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/score.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7642 (7.5K) [text/plain]\n",
            "Saving to: ‘score.py.12’\n",
            "\n",
            "score.py.12         100%[===================>]   7.46K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-07-14 20:26:11 (126 MB/s) - ‘score.py.12’ saved [7642/7642]\n",
            "\n",
            "--2019-07-14 20:26:12--  https://github.com/SchattenGenie/mlhep2019_2_phase/raw/master/analysis/embedder.tp\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/embedder.tp [following]\n",
            "--2019-07-14 20:26:12--  https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/embedder.tp\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 569697 (556K) [application/octet-stream]\n",
            "Saving to: ‘embedder.tp.12’\n",
            "\n",
            "embedder.tp.12      100%[===================>] 556.34K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-07-14 20:26:12 (10.4 MB/s) - ‘embedder.tp.12’ saved [569697/569697]\n",
            "\n",
            "--2019-07-14 20:26:13--  https://github.com/SchattenGenie/mlhep2019_2_phase/raw/master/analysis/generator.py\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/generator.py [following]\n",
            "--2019-07-14 20:26:14--  https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/generator.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1514 (1.5K) [text/plain]\n",
            "Saving to: ‘generator.py.12’\n",
            "\n",
            "generator.py.12     100%[===================>]   1.48K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-07-14 20:26:14 (239 MB/s) - ‘generator.py.12’ saved [1514/1514]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXxnaK7TH6vO",
        "colab_type": "code",
        "outputId": "c122b28f-1c1e-4763-fe37-1ecef98de243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile .comet.config\n",
        "[comet]\n",
        "api_key=mIel5ZAPOioTs0Cij75dSSQXs\n",
        "logging_file = /tmp/comet.log\n",
        "logging_file_level = info\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting .comet.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlDzipgxH9kV",
        "colab_type": "code",
        "outputId": "32c57c3b-261e-4d94-faee-2929ccabbc6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "! [ ! -z \"$COLAB_GPU\" ] && pip install skorch comet_ml"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: skorch in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: comet_ml in /usr/local/lib/python3.6/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.8.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.16.4)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (4.28.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.21.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.12.0)\n",
            "Requirement already satisfied: websocket-client>=0.55.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.56.0)\n",
            "Requirement already satisfied: comet-git-pure>=0.19.11 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.19.11)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (7.352.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.21.0)\n",
            "Requirement already satisfied: netifaces>=0.10.7 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.10.9)\n",
            "Requirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.6.0)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.0.3)\n",
            "Requirement already satisfied: everett[ini]>=1.0.1; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (0.13.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from comet-git-pure>=0.19.11->comet_ml) (2019.6.16)\n",
            "Requirement already satisfied: urllib3>=1.23 in /usr/local/lib/python3.6/dist-packages (from comet-git-pure>=0.19.11->comet_ml) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (2.8)\n",
            "Requirement already satisfied: configobj; extra == \"ini\" in /usr/local/lib/python3.6/dist-packages (from everett[ini]>=1.0.1; python_version >= \"3.0\"->comet_ml) (5.0.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOlzCD-oIA-S",
        "colab_type": "code",
        "outputId": "638c9385-fc43-453e-a4fd-524da2eff06d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from comet_ml import Experiment\n",
        "experiment = Experiment(project_name=\"BayesGAN\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/satoruk-icepp/bayesgan/5de8ad08d1e24b84aa0571c3b7e59cb7\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLgVy1i9zZiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE         = 150\n",
        "N_EPOCH            = 200\n",
        "EnergyDepositScale = 20000\n",
        "learning_rate = 0.0002\n",
        "dnoise_alpha = 0.0001\n",
        "gnoise_alpha = 0.0001\n",
        "NOISE_DIM = 10\n",
        "Ngen = 1\n",
        "Ndisc = 1\n",
        "PXscale = 30\n",
        "PYscale = 30\n",
        "PZscale = 100\n",
        "XPosscale = 10\n",
        "YPosscale = 10\n",
        "Nresblock = 5\n",
        "params={'batch_size': BATCH_SIZE,\n",
        "        'epochs': N_EPOCH,\n",
        "        'energyscale': EnergyDepositScale,\n",
        "        'noise_dim': NOISE_DIM,\n",
        "        'learning_rate':learning_rate,\n",
        "        'dnoise_alpha':dnoise_alpha,\n",
        "        'gnoise_alpha':gnoise_alpha,\n",
        "        'Ngen':Ngen,\n",
        "        'Ndisc':Ndisc,\n",
        "        'PXscale':PXscale,\n",
        "        'PYscale':PYscale,\n",
        "        'PZscale':PZscale,\n",
        "        'XPosscale':XPosscale,\n",
        "        'YPosscale':YPosscale,\n",
        "        'Nresblock':Nresblock\n",
        "}\n",
        "experiment.log_parameters(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLY8nIkZLn24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skorch import NeuralNetClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "790_h5rSmDLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as utils\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "sns.set()\n",
        "\n",
        "def one_hot(a, num_classes):\n",
        "    return np.squeeze(np.eye(num_classes)[a.reshape(-1)])\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW0lyRVGmDLC",
        "colab_type": "code",
        "outputId": "4db85fab-dd75-40cc-d486-538570cda12b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giyM_o8bmDLI",
        "colab_type": "code",
        "outputId": "2cb73018-6f30-408f-82c8-270c2ddca4f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJbcY6IwmDLK",
        "colab_type": "text"
      },
      "source": [
        "## Data pathes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5muy7MJmDLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_path = '/gdrive/My Drive/mlhep2019_gan/data_train.npz'\n",
        "val_data_path = '/gdrive/My Drive/mlhep2019_gan/data_val.npz'\n",
        "test_data_path = '/gdrive/My Drive/mlhep2019_gan/data_test.npz'\n",
        "\n",
        "# train_data_path = '../data_train.npz'\n",
        "# val_data_path = '../data_val.npz'\n",
        "# test_data_path = '../data_test.npz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqklR3OHmDLM",
        "colab_type": "text"
      },
      "source": [
        "# Loading data\n",
        "\n",
        "Data is stored in `.npz`-format which is a special filetype for persisting multiple NumPy arrays on disk. \n",
        "\n",
        "More info: https://docs.scipy.org/doc/numpy/reference/generated/numpy.lib.format.html#module-numpy.lib.format.\n",
        "\n",
        "File `dat_train.npz` contains four arrays: \n",
        "\n",
        "  * `EnergyDeposit` - images of calorimeters responses\n",
        "  * `ParticleMomentum` - $p_x, p_y, p_z$ of initial partice\n",
        "  * `ParticlePoint` - $x, y$ of initial particle\n",
        "  * `ParticlePDG` - particle type(either $e^-$ or $\\gamma$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcLIRNvMmDLN",
        "colab_type": "code",
        "outputId": "a4f701fb-7b1c-45a7-b283-12620cbee266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# N = 1000\n",
        "\n",
        "data_train = np.load(train_data_path, allow_pickle=True)\n",
        "print(list(data_train.keys()))\n",
        "# N = len(data_train)\n",
        "N=50250\n",
        "# [data_size, 900]\n",
        "EnergyDeposit = data_train['EnergyDeposit'][:N]\n",
        "# reshaping it as [data_size, channels, img_size_x, img_size_y]\n",
        "# channels are needed for pytorch conv2d-layers\n",
        "EnergyDeposit = EnergyDeposit.reshape(-1, 1, 30, 30)\n",
        "\n",
        "# [data_size, 3]\n",
        "ParticleMomentum = data_train['ParticleMomentum'][:N]\n",
        "\n",
        "# [data_size, 2]\n",
        "ParticlePoint = data_train['ParticlePoint'][:, :2][:N]\n",
        "\n",
        "# [data_size, 1]\n",
        "ParticlePDG = data_train['ParticlePDG'][:N]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['EnergyDeposit', 'ParticlePoint', 'ParticleMomentum', 'ParticlePDG']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz8A_3Znvyu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(EnergyDeposit.shape)\n",
        "# EnergyDeposit_1d = EnergyDeposit.reshape(-1,900).sum(axis=1)\n",
        "# plt.hist(EnergyDeposit_1d)\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p85ufIdJFrn8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "126dba87-ccbc-414b-f9a1-fed4ce5e5e1a"
      },
      "source": [
        "# print(EnergyDeposit.shape)\n",
        "# EnergyDeposit_1d = EnergyDeposit.reshape(-1,900).sum(axis=1)\n",
        "# plt.hist(ParticleMomentum[:,2])\n",
        "plt.hist(ParticlePoint[:,0])\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEBCAYAAACAIClPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni0Ri++gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExAROHySmDLP",
        "colab_type": "text"
      },
      "source": [
        "## Load it to pytorch `DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtEr15sdmDLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EnergyDeposit = torch.tensor(EnergyDeposit).float()\n",
        "ParticleMomentum = torch.tensor(ParticleMomentum).float()\n",
        "ParticlePoint = torch.tensor(ParticlePoint).float()\n",
        "\n",
        "\n",
        "calo_dataset = utils.TensorDataset(EnergyDeposit, ParticleMomentum, ParticlePoint)\n",
        "calo_dataloader = torch.utils.data.DataLoader(calo_dataset, batch_size=BATCH_SIZE, pin_memory=True, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crC_kDGkmDLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b in calo_dataloader:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inm6pj7DmDLU",
        "colab_type": "text"
      },
      "source": [
        "## Training GAN\n",
        "###### ...is not a simple matter\n",
        "\n",
        "It depends on architecture, loss, instance noise, augmentation and even luck(recommend to take a look https://arxiv.org/pdf/1801.04406.pdf)\n",
        "\n",
        "\n",
        "In this notebook I have prepared some basic parts that you could use for your experiments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU8Gxli9mDLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TASKS = ['KL', 'REVERSED_KL', 'WASSERSTEIN', 'BAYESIAN']\n",
        "\n",
        "TASK = 'BAYESIAN'\n",
        "# TASK = 'WASSERSTEIN'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99KKDCxvmDLY",
        "colab_type": "text"
      },
      "source": [
        "### Additional things for Wasserstein GAN\n",
        "\n",
        "To make `Wasserstein`-GAN works we suggest three options:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0_bjx8ZmDLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIPSITZ_WEIGHTS = False\n",
        "clamp_lower, clamp_upper = -0.01, 0.01\n",
        "\n",
        "\n",
        "# https://arxiv.org/abs/1704.00028\n",
        "GRAD_PENALTY = True\n",
        "\n",
        "# https://arxiv.org/abs/1705.09367\n",
        "ZERO_CENTERED_GRAD_PENALTY = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNKTOTNkmDLb",
        "colab_type": "text"
      },
      "source": [
        "#### Small hack that can speed-up training and improve generalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOq11rptmDLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://arxiv.org/abs/1610.04490\n",
        "INSTANCE_NOISE = True\n",
        "\n",
        "def add_instance_noise(data, std=0.01):\n",
        "    return data + torch.distributions.Normal(0, std).sample(data.shape).to(device)\n",
        "\n",
        "def NormalizeImage(image):\n",
        "    norm_image = []\n",
        "    for singleimage in image:\n",
        "        meanimage = torch.mean(singleimage)\n",
        "        sumimage  = torch.sum(singleimage)        \n",
        "        maximage  = torch.max(singleimage)\n",
        "        minimage  = torch.min(singleimage)\n",
        "        singleimage = singleimage/sumimage\n",
        "        norm_image.append([sumimage/EnergyDepositScale])\n",
        "    norm_image = torch.Tensor(norm_image)\n",
        "    norm_image.view(-1,1,1)\n",
        "    return image, norm_image\n",
        "\n",
        "def NormalizeMomentumPoint(MomentumPoint):\n",
        "    MomentumPoint[0]/=PXscale\n",
        "    MomentumPoint[1]/=PYscale\n",
        "    MomentumPoint[2]/=PZscale    \n",
        "    MomentumPoint[3]/=XPosscale    \n",
        "    MomentumPoint[4]/=YPosscale        \n",
        "    return MomentumPoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYW8x_ln2OFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _assert_no_grad(variable):\n",
        "    assert not variable.requires_grad, \\\n",
        "        \"nn criterions don't compute the gradient w.r.t. targets - please \" \\\n",
        "        \"mark these variables as volatile or not requiring gradients\"\n",
        "\n",
        "class ComplementCrossEntropyLoss(torch.nn.Module):\n",
        "  # Note: This is the cross entropy of the sum of all probabilities of other indices, except for the \n",
        "  # This is used in Bayesian GAN semi-supervised learning\n",
        "    def __init__(self, except_index=None, weight=None, ignore_index=-100, size_average=True, reduce=True):\n",
        "        super(ComplementCrossEntropyLoss, self).__init__()\n",
        "        self.except_index = except_index\n",
        "        self.weight = weight\n",
        "        self.ignore_index = ignore_index\n",
        "        self.size_average = size_average\n",
        "        self.reduce = reduce\n",
        "\n",
        "    def forward(self, input, target=None):\n",
        "    # Use target if not None, else use self.except_index\n",
        "        if target is not None:\n",
        "            _assert_no_grad(target)\n",
        "        else:\n",
        "            assert self.except_index is not None\n",
        "            target = torch.autograd.Variable(torch.LongTensor(input.data.shape[0]).fill_(self.except_index).cuda())\n",
        "            result = torch.nn.functional.nll_loss(\n",
        "            torch.log(1. - torch.nn.functional.softmax(input) + 1e-4), \n",
        "            target, weight=self.weight, \n",
        "            size_average=self.size_average, \n",
        "            ignore_index=self.ignore_index)\n",
        "        return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWQqgdmQ2QDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "#from distributions import Normal\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class NoiseLoss(torch.nn.Module):\n",
        "  # need the scale for noise standard deviation\n",
        "  # scale = noise  std\n",
        "    def __init__(self, params, scale=None, observed=None):\n",
        "        super(NoiseLoss, self).__init__()\n",
        "        # initialize the distribution for each parameter\n",
        "        #self.distributions = []\n",
        "        self.noises = []\n",
        "        for param in params:\n",
        "            noise = 0*param.data.cuda() # will fill with normal at each forward\n",
        "            self.noises.append(noise)\n",
        "        if scale is not None:\n",
        "            self.scale = scale\n",
        "        else:\n",
        "            self.scale = 1.\n",
        "        self.observed = observed\n",
        "\n",
        "    def forward(self, params, scale=None, observed=None):\n",
        "    # scale should be sqrt(2*alpha/eta)\n",
        "    # where eta is the learning rate and alpha is the strength of drag term\n",
        "        if scale is None:\n",
        "            scale = self.scale\n",
        "        if observed is None:\n",
        "            observed = self.observed\n",
        "\n",
        "        assert scale is not None, \"Please provide scale\"\n",
        "        noise_loss = 0.0\n",
        "        for noise, var in zip(self.noises, params):\n",
        "            # This is scale * z^T*v\n",
        "            # The derivative wrt v will become scale*z\n",
        "            _noise = noise.normal_(0,1)\n",
        "#             print(_noise.shape,var.shape)\n",
        "#             print(torch.sum(Variable(_noise)*var))\n",
        "            noise_loss += scale*torch.sum(Variable(_noise)*var)\n",
        "        noise_loss /= observed\n",
        "        return noise_loss\n",
        "\n",
        "class PriorLoss(torch.nn.Module):\n",
        "  # negative log Gaussian prior\n",
        "    def __init__(self, prior_std=1., observed=None):\n",
        "        super(PriorLoss, self).__init__()\n",
        "        self.observed = observed\n",
        "        self.prior_std = prior_std\n",
        "\n",
        "    def forward(self, params, observed=None):\n",
        "        if observed is None:\n",
        "            observed = self.observed\n",
        "        prior_loss = 0.0\n",
        "        for var in params:\n",
        "#             print(var.shape,self.prior_std)\n",
        "#             print(var*var)\n",
        "            prior_loss += torch.sum(var*var/(self.prior_std*self.prior_std))\n",
        "#             prior_loss += torch.sum((var**2)/(self.prior_std**2))\n",
        "#             prior_loss += torch.sum(var.pow(2)/(self.prior_std**2))\n",
        "        prior_loss /= observed\n",
        "        return prior_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA5ResSp2WXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "# use the default index = 0 - equivalent to summing all other probabilities\n",
        "criterion_comp = ComplementCrossEntropyLoss(except_index=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT8YWKN5mDLg",
        "colab_type": "text"
      },
      "source": [
        "## Defining discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skiem1EXmDLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelD, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
        "        self.bn3 = nn.BatchNorm2d(64)        \n",
        "        self.conv4 = nn.Conv2d(64, 64, 2)\n",
        "        self.conv5 = nn.Conv2d(64, 32, 2)        \n",
        "        \n",
        "        # size\n",
        "        self.fc1 = nn.Linear(2592 + 5+1, 1024) \n",
        "        self.fc2 = nn.Linear(1024, 512)         \n",
        "        self.fc3 = nn.Linear(512, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 2)\n",
        "        \n",
        "        self.bn_fc1 = nn.BatchNorm1d(128)\n",
        "        \n",
        "    def forward(self, EnergyDeposit_raw, ParticleMomentum_ParticlePoint):\n",
        "        EnergyDeposit, norm_image = NormalizeImage(EnergyDeposit_raw)\n",
        "        EnergyDeposit = self.dropout(F.leaky_relu(self.bn1(self.conv1(EnergyDeposit))))\n",
        "        EnergyDeposit = self.dropout(F.leaky_relu(self.bn2(self.conv2(EnergyDeposit))))\n",
        "#         EnergyDeposit = self.dropout(F.leaky_relu(self.conv1(EnergyDeposit)))\n",
        "#         EnergyDeposit = self.dropout(F.leaky_relu(self.conv2(EnergyDeposit)))\n",
        "        EnergyDeposit = F.leaky_relu(self.bn3(self.conv3(EnergyDeposit)))\n",
        "        EnergyDeposit = F.leaky_relu(self.conv4(EnergyDeposit)) # 32, 9, 9\n",
        "        EnergyDeposit = F.leaky_relu(self.conv5(EnergyDeposit)) # 32, 9, 9        \n",
        "        EnergyDeposit = EnergyDeposit.view(len(EnergyDeposit), -1)\n",
        "        ParticleMomentum_ParticlePoint = NormalizeMomentumPoint(ParticleMomentum_ParticlePoint)        \n",
        "        t = torch.cat([EnergyDeposit, ParticleMomentum_ParticlePoint,norm_image.cuda()], dim=1)\n",
        "        \n",
        "        t = F.leaky_relu(self.fc1(t))\n",
        "        t = F.leaky_relu(self.fc2(t))\n",
        "        t = F.leaky_relu(self.bn_fc1(self.fc3(t)))\n",
        "        t = F.leaky_relu(self.fc4(t))\n",
        "#         if TASK == 'WASSERSTEIN' or TASK == 'BAYESIAN':\n",
        "        return self.fc5(t)\n",
        "#         else:\n",
        "#             return torch.sigmoid(self.fc5(t))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4_WffK-mDLi",
        "colab_type": "text"
      },
      "source": [
        "## Defining generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrHzXEggAwPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReducedConv(nn.Module):\n",
        "    def __init__(self,input_size,output_size, input_dim, output_dim,kernel_size):\n",
        "        super(ReducedConv, self).__init__()\n",
        "        scale = float(output_dim+kernel_size-3)/float(input_dim)\n",
        "        self.ups = nn.Upsample(scale_factor = scale,mode = 'bilinear',align_corners=False )\n",
        "        self.ref = nn.ReflectionPad2d(1)\n",
        "        self.conv = nn.Conv2d(input_size,output_size,kernel_size)\n",
        "    def forward(self,x):\n",
        "        return self.conv(self.ref(self.ups(x)))\n",
        "#         return self.ref(self.ups(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbpW5fVPAxSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self,input_size):\n",
        "        super(ResidualBlock, self).__init__()        \n",
        "        self.conv1 = nn.Conv2d(input_size,input_size,3,padding=1)\n",
        "#         self.conv2 = nn.Conv2d(input_size,input_size,3,padding=1)\n",
        "    def forward(self,xraw):\n",
        "        x = F.leaky_relu(self.conv1(xraw))\n",
        "        x = F.leaky_relu(self.conv1(x)+xraw)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15gNgQ-ymDLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelGConvTranspose(nn.Module):\n",
        "    def __init__(self, z_dim):\n",
        "        self.z_dim = z_dim\n",
        "        super(ModelGConvTranspose, self).__init__()\n",
        "        self.fc1 = nn.Linear(self.z_dim + 2 + 3, 64)\n",
        "        self.fc2 = nn.Linear(64, 128)\n",
        "        self.fc3 = nn.Linear(128, 512)\n",
        "        self.fc4 = nn.Linear(512, 20736)\n",
        "        \n",
        "        self.trconv1 = nn.ConvTranspose2d(256, 256, 3, stride=2, output_padding=1)\n",
        "        self.trconv2 = nn.ConvTranspose2d(256, 128, 3)\n",
        "        self.trconv3 = nn.ConvTranspose2d(128, 64, 3)\n",
        "        self.trconv4 = nn.ConvTranspose2d(64, 16, 2)\n",
        "        self.trconv5 = nn.ConvTranspose2d(16, 16, 2)\n",
        "        self.trconv6 = nn.ConvTranspose2d(16, 16, 2)\n",
        "        self.trconv7 = nn.ConvTranspose2d(16, 16, 2)        \n",
        "#         self.trconv8 = nn.ConvTranspose2d(16, 1, 3)\n",
        "        self.resblock = ResidualBlock(16)\n",
        "        self.resconv1 = ReducedConv(16,16,26,28,3)\n",
        "        self.resconv2 = ReducedConv(16,1,28,30,3)\n",
        "        \n",
        "    def forward(self, z, ParticleMomentum_ParticlePoint):\n",
        "        ParticleMomentum_ParticlePoint = NormalizeMomentumPoint(ParticleMomentum_ParticlePoint)\n",
        "        x = F.leaky_relu(self.fc1(\n",
        "            torch.cat([z, ParticleMomentum_ParticlePoint], dim=1)\n",
        "        ))\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        x = F.leaky_relu(self.fc3(x))\n",
        "        x = F.leaky_relu(self.fc4(x))\n",
        "        \n",
        "        EnergyDeposit = x.view(-1, 256, 9, 9)\n",
        "        \n",
        "        EnergyDeposit = F.leaky_relu(self.trconv1(EnergyDeposit))\n",
        "        EnergyDeposit = F.leaky_relu(self.trconv2(EnergyDeposit))\n",
        "        EnergyDeposit = F.leaky_relu(self.trconv3(EnergyDeposit))\n",
        "        EnergyDeposit = F.leaky_relu(self.trconv4(EnergyDeposit))\n",
        "        EnergyDeposit = F.leaky_relu(self.trconv5(EnergyDeposit))\n",
        "\n",
        "        for i in range(Nresblock):\n",
        "            EnergyDeposit = self.resblock(EnergyDeposit)\n",
        "#         EnergyDeposit = F.leaky_relu(self.trconv6(EnergyDeposit))\n",
        "#         EnergyDeposit = F.leaky_relu(self.conv1(self.ref(self.ups(EnergyDeposit))))\n",
        "        EnergyDeposit = F.leaky_relu(self.resconv1(EnergyDeposit))\n",
        "#         EnergyDeposit = F.leaky_relu(self.conv7(EnergyDeposit))                \n",
        "        EnergyDeposit = self.resconv2(EnergyDeposit)\n",
        "#         EnergyDeposit = self.trconv7(EnergyDeposit)\n",
        "\n",
        "        return EnergyDeposit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys1Z545TmDLl",
        "colab_type": "text"
      },
      "source": [
        "## Check our models on one batch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe748y6nmDLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "gens = []\n",
        "discs = []\n",
        "\n",
        "for i in range(Ngen):\n",
        "    gen = ModelGConvTranspose(z_dim=NOISE_DIM).to(device)\n",
        "    gens.append(gen)\n",
        "# print(gens[0].state_dict())\n",
        "\n",
        "for i in range(Ndisc):\n",
        "    disc = ModelD().to(device)\n",
        "#     disc = NeuralNetClassifier(\n",
        "#         ModelD,\n",
        "#         max_epochs=20,\n",
        "#         module__num_units=10,\n",
        "#         lr=0.1,\n",
        "#         device='cuda',  # comment this to train with CPU\n",
        "#     )\n",
        "    discs.append(disc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUk-rAs1mDLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b = EnergyDeposit_b.to(device), \\\n",
        "                                                       ParticleMomentum_b.to(device), \\\n",
        "                                                       ParticlePoint_b.to(device)\n",
        "ParticleMomentum_ParticlePoint_b = torch.cat([ParticleMomentum_b.to(device), ParticlePoint_b.to(device)], dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxV-qa2YmDLq",
        "colab_type": "code",
        "outputId": "908cf168-24b5-4e46-dc3e-7f41f63cf5a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "EnergyDeposit_b.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([150, 1, 30, 30])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcrCO7wRmDLv",
        "colab_type": "code",
        "outputId": "98d61a08-2c49-4323-dc66-9658545ff9e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "discs[0](EnergyDeposit_b, ParticleMomentum_ParticlePoint_b).shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([150, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxagWRP6mDLx",
        "colab_type": "code",
        "outputId": "fa4d9658-3530-4f68-d9e3-f36543d3cda9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "noise = torch.randn(len(EnergyDeposit_b), NOISE_DIM).to(device)\n",
        "gens[0](noise, ParticleMomentum_ParticlePoint_b).shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([150, 1, 30, 30])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgnGKjGF4MPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gprior_criterion = PriorLoss(prior_std=1., observed=10000.)\n",
        "gnoise_criterion = NoiseLoss(params=gens[0].parameters(), scale=math.sqrt(2*gnoise_alpha/learning_rate), observed=10000.)\n",
        "dprior_criterion = PriorLoss(prior_std=1., observed=10000.)\n",
        "dnoise_criterion = NoiseLoss(params=discs[0].parameters(), scale=math.sqrt(2*dnoise_alpha*learning_rate), observed=10000.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCaPksu4mDLz",
        "colab_type": "text"
      },
      "source": [
        "## Defining optimiser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXVckXSZmDL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learning_rate_dis = 1e-5\n",
        "# learning_rate_gen = 1e-5\n",
        "gens_opt = []\n",
        "for gen in gens:\n",
        "    gen_opt = optim.Adam(gen.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
        "    gens_opt.append(gen_opt)\n",
        "# gen_opt = optim.Adam(gen.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
        "# g_optimizer = optim.RMSprop(discriminator.parameters(), lr=learning_rate_dis, weight_decay=1e-6)\n",
        "# d_optimizer = optim.SGD(discriminator.parameters(), lr=learning_rate_dis, weight_decay=1e-6)\n",
        "# d_optimizer = optim.RMSprop(discriminator.parameters(), lr=learning_rate_dis, weight_decay=1e-6)\n",
        "discs_opt = []\n",
        "for disc in discs:\n",
        "    disc_opt = optim.Adam(disc.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
        "    discs_opt.append(disc_opt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpBbUF9DmDL2",
        "colab_type": "text"
      },
      "source": [
        "## Load scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9v-IZO8mDL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from prd_score import compute_prd, compute_prd_from_embedding, _prd_to_f_beta\n",
        "from sklearn.metrics import auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c18oWujomDL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def run_training(epochs):\n",
        "\n",
        "    # ===========================\n",
        "    # IMPORTANT PARAMETER:\n",
        "    # Number of D updates per G update\n",
        "    # ===========================\n",
        "\n",
        "#     gan_losses = GANLosses(TASK, device)\n",
        "    ibatch = 0\n",
        "    dis_epoch_loss = []\n",
        "    gen_epoch_loss = []\n",
        "    predictions_dis = []\n",
        "    predictions_gen = []\n",
        "    prd_auc = []  \n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        first = True\n",
        "        \n",
        "        for EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b in calo_dataloader:\n",
        "            EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b = EnergyDeposit_b.to(device), \\\n",
        "                                                                   ParticleMomentum_b.to(device), \\\n",
        "                                                                   ParticlePoint_b.to(device)\n",
        "            ParticleMomentum_ParticlePoint_b = torch.cat([ParticleMomentum_b.to(device), ParticlePoint_b.to(device)], dim=1)\n",
        "            for disc, disc_opt in zip(discs,discs_opt):                \n",
        "                output = disc(EnergyDeposit_b,ParticleMomentum_ParticlePoint_b)\n",
        "                disc_real = criterion_comp(output)\n",
        "                disc_real.backward()\n",
        "                EnergyDeposit_gens = []\n",
        "                ParticleMomentum_ParticlePoint_bs = []\n",
        "                for gen in gens:\n",
        "                    noise = torch.randn(len(EnergyDeposit_b), NOISE_DIM).to(device)\n",
        "                    EnergyDeposit_gen = gen(noise, ParticleMomentum_ParticlePoint_b)\n",
        "                    EnergyDeposit_gens.append(EnergyDeposit_gen)\n",
        "                    ParticleMomentum_ParticlePoint_bs.append(ParticleMomentum_ParticlePoint_b)\n",
        "                EnergyDeposit_gens = torch.cat(EnergyDeposit_gens)\n",
        "                ParticleMomentum_ParticlePoint_bs = torch.cat(ParticleMomentum_ParticlePoint_bs)\n",
        "\n",
        "                output = disc(EnergyDeposit_gens.detach(),ParticleMomentum_ParticlePoint_bs)\n",
        "                labelv_fake = Variable(torch.LongTensor(EnergyDeposit_gens.data.shape[0]).cuda().fill_(0))\n",
        "                disc_fake = criterion(output, labelv_fake.cuda())\n",
        "                disc_fake.backward()\n",
        "\n",
        "                output = disc(EnergyDeposit_b.detach(),ParticleMomentum_ParticlePoint_b)\n",
        "                labelv_real = Variable(torch.LongTensor(EnergyDeposit_b.data.shape[0]).cuda().fill_(1))\n",
        "                err_sup = criterion(output, labelv_real.cuda())\n",
        "                err_sup.backward()\n",
        "                disc_prior = dprior_criterion(disc.parameters())\n",
        "                disc_prior.backward()\n",
        "                disc_noise = dnoise_criterion(disc.parameters())\n",
        "                disc_noise.backward()\n",
        "                disc_loss = disc_real + disc_fake + err_sup + disc_prior + disc_noise\n",
        "                disc_opt.step()\n",
        "\n",
        "            dis_epoch_loss.append(disc_loss.item())\n",
        "            experiment.log_metric(\"d_loss\", disc_loss.item(),step=ibatch)\n",
        "            predictions_dis.append(\n",
        "                list(disc(EnergyDeposit_b, ParticleMomentum_ParticlePoint_b).detach().cpu().numpy().ravel())\n",
        "            )\n",
        "\n",
        "            predictions_gen.append(\n",
        "                list(disc(EnergyDeposit_gen, ParticleMomentum_ParticlePoint_b).detach().cpu().numpy().ravel())\n",
        "            )\n",
        "            \n",
        "            \n",
        "            for gen, gen_opt in zip(gens,gens_opt):\n",
        "                gen_opt.zero_grad()\n",
        "                gen_losses = []\n",
        "                for disc in discs:\n",
        "                    noise = torch.randn(len(EnergyDeposit_b), NOISE_DIM).to(device)\n",
        "                    EnergyDeposit_gen = gen(noise, ParticleMomentum_ParticlePoint_b)\n",
        "                    output = disc(EnergyDeposit_gen,ParticleMomentum_ParticlePoint_b)\n",
        "                    gen_loss = criterion_comp(output)\n",
        "                    gen_loss += gprior_criterion(gen.parameters())\n",
        "                    gen_loss += gnoise_criterion(gen.parameters())    \n",
        "                    gen_loss.backward()\n",
        "#                     gen_losses.append(gen_loss)\n",
        "#                 print(gen_losses)\n",
        "#                 gen_losses = torch.sum(gen_losses)\n",
        "#                 gen_losses.backward()\n",
        "                gen_opt.step()\n",
        "                \n",
        "            gen_epoch_loss.append(gen_loss.item())\n",
        "            experiment.log_metric(\"g_loss\", gen_loss.item(),step=ibatch)            \n",
        "            EnergyDeposit_gen_sample = EnergyDeposit_gens                    \n",
        "            EnergyDeposit_dat_sample = EnergyDeposit_b\n",
        "            if first:\n",
        "\n",
        "                precision, recall = compute_prd_from_embedding(\n",
        "                    EnergyDeposit_gen.detach().cpu().numpy().reshape(BATCH_SIZE, -1), \n",
        "                    EnergyDeposit_b.detach().cpu().numpy().reshape(BATCH_SIZE, -1),\n",
        "                    num_clusters=30,\n",
        "                    num_runs=100)\n",
        "                prd_auc.append(auc(precision, recall))\n",
        "                generator_cpu = ModelGConvTranspose(z_dim=NOISE_DIM)\n",
        "                generator_cpu.load_state_dict(gens[0].state_dict())\n",
        "#                 generator_cpu.eval()\n",
        "                torch.save(generator_cpu.state_dict(), './gan%d.pt'%(epoch))\n",
        "                first=False\n",
        "            ibatch += 1\n",
        "            clear_output()\n",
        "            plt.figure(figsize=(15,12))\n",
        "            grid = plt.GridSpec(2, 3, wspace=0.4, hspace=0.3)\n",
        "            plt.subplot(grid[0,0])\n",
        "            plt.semilogy(dis_epoch_loss, label='dis_epoch_loss')\n",
        "            plt.semilogy(gen_epoch_loss, label='gen_epoch_loss')\n",
        "            plt.legend()\n",
        "\n",
        "            plt.subplot(grid[0,1])\n",
        "    #         plt.xlim(-1,2)\n",
        "            plt.hist(predictions_dis[-1], bins=40, label='dis_epoch_loss',color=\"blue\")\n",
        "            plt.hist(predictions_gen[-1], bins=40, label='gen_epoch_loss',color=\"orange\")\n",
        "            plt.legend()\n",
        "\n",
        "            plt.subplot(grid[0,2])\n",
        "            plt.plot(prd_auc, label='prd_auc')\n",
        "            plt.ylim(0,1)\n",
        "            plt.legend()\n",
        "    #         plt.show()\n",
        "\n",
        "            plt.subplot(grid[1, 0])\n",
        "            plt.imshow(EnergyDeposit_gen_sample[0][0].cpu().detach().numpy())\n",
        "            plt.subplot(grid[1, 1])\n",
        "            plt.imshow(EnergyDeposit_dat_sample[0][0].cpu().detach().numpy())\n",
        "            experiment.log_figure(figure=plt)\n",
        "            plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "zPLcnlKhmDMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with experiment.train():\n",
        "    run_training(N_EPOCH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT2fiNDMmDMJ",
        "colab_type": "text"
      },
      "source": [
        "#### Transfer generator on CPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTumKz8smDMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_cpu = ModelGConvTranspose(z_dim=NOISE_DIM)\n",
        "# generator_cpu.load_state_dict(generator.state_dict())\n",
        "generator_cpu.load_state_dict(torch.load('/content/gan21.pt'))\n",
        "generator_cpu.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrzMuZGzmDMM",
        "colab_type": "text"
      },
      "source": [
        "### Save model on disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXwtnaSBmDMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(generator_cpu.state_dict(), './gan.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nITR2bZwmDMO",
        "colab_type": "text"
      },
      "source": [
        "## Making predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihAqZQxvmDMP",
        "colab_type": "text"
      },
      "source": [
        "#### Validation predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "rVhVrubhmDMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_val = np.load(val_data_path, allow_pickle=True)\n",
        "ParticleMomentum_val = torch.tensor(data_val['ParticleMomentum']).float()\n",
        "ParticlePoint_val = torch.tensor(data_val['ParticlePoint'][:, :2]).float()\n",
        "ParticleMomentum_ParticlePoint_val = torch.cat([ParticleMomentum_val, ParticlePoint_val], dim=1)\n",
        "calo_dataset_val = utils.TensorDataset(ParticleMomentum_ParticlePoint_val)\n",
        "calo_dataloader_val = torch.utils.data.DataLoader(calo_dataset_val, batch_size=1024, shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    EnergyDeposit_val = []\n",
        "    for ParticleMomentum_ParticlePoint_val_batch in tqdm(calo_dataloader_val):\n",
        "        noise = torch.randn(len(ParticleMomentum_ParticlePoint_val_batch[0]), NOISE_DIM)\n",
        "        EnergyDeposit_val_batch = generator_cpu(noise, ParticleMomentum_ParticlePoint_val_batch[0]).detach().numpy()\n",
        "        EnergyDeposit_val.append(EnergyDeposit_val_batch)\n",
        "    np.savez_compressed('./data_val_prediction.npz', \n",
        "                        EnergyDeposit=np.concatenate(EnergyDeposit_val, axis=0).reshape(-1, 30, 30))\n",
        "\n",
        "    del EnergyDeposit_val\n",
        "del data_val; del ParticleMomentum_val; del ParticlePoint_val; del ParticleMomentum_ParticlePoint_val;\n",
        "del calo_dataset_val; calo_dataloader_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz2T9U3-mDMS",
        "colab_type": "text"
      },
      "source": [
        "#### Test predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "666U1Q_smDMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test = np.load(test_data_path, allow_pickle=True)\n",
        "ParticleMomentum_test = torch.tensor(data_test['ParticleMomentum']).float()\n",
        "ParticlePoint_test = torch.tensor(data_test['ParticlePoint'][:, :2]).float()\n",
        "ParticleMomentum_ParticlePoint_test = torch.cat([ParticleMomentum_test, ParticlePoint_test], dim=1)\n",
        "calo_dataset_test = utils.TensorDataset(ParticleMomentum_ParticlePoint_test)\n",
        "calo_dataloader_test = torch.utils.data.DataLoader(calo_dataset_test, batch_size=1024, shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    EnergyDeposit_test = []\n",
        "    for ParticleMomentum_ParticlePoint_test_batch in tqdm(calo_dataloader_test):\n",
        "        noise = torch.randn(len(ParticleMomentum_ParticlePoint_test_batch[0]), NOISE_DIM)\n",
        "        EnergyDeposit_test_batch = generator_cpu(noise, ParticleMomentum_ParticlePoint_test_batch[0]).detach().numpy()\n",
        "        EnergyDeposit_test.append(EnergyDeposit_test_batch)\n",
        "    np.savez_compressed('./data_test_prediction.npz', \n",
        "                        EnergyDeposit=np.concatenate(EnergyDeposit_test, axis=0).reshape(-1, 30, 30))\n",
        "\n",
        "    del EnergyDeposit_test\n",
        "del data_test; del ParticleMomentum_test; del ParticlePoint_test; del ParticleMomentum_ParticlePoint_test;\n",
        "del calo_dataset_test; calo_dataloader_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AIKCQMtmDMU",
        "colab_type": "text"
      },
      "source": [
        "## `zip-zip` files together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvbj0nhzmDMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip solution.zip data_val_prediction.npz data_test_prediction.npz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG-4EvGOmDMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import FileLink\n",
        "FileLink('./solution.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGp0K2LrmDMY",
        "colab_type": "text"
      },
      "source": [
        "# A few words about metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_j_38JamDMa",
        "colab_type": "text"
      },
      "source": [
        "### Lets generate some fake data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kyqaIyhmDMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise = torch.randn(len(ParticleMomentum_b), NOISE_DIM)\n",
        "ParticleMomentum_ParticlePoint = torch.cat([ParticleMomentum, \n",
        "                                            ParticlePoint], dim=1)\n",
        "EnergyDeposit_gen = generator_cpu(noise, ParticleMomentum_ParticlePoint_b.cpu())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s353zPylmDMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EnergyDeposit_gen = EnergyDeposit_gen.detach().cpu().numpy().reshape(-1, 30, 30)\n",
        "EnergyDeposit = EnergyDeposit.detach().cpu().numpy().reshape(-1, 30, 30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TD90ylsmDMd",
        "colab_type": "text"
      },
      "source": [
        "#### Plot one image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxhjGZGYmDMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(EnergyDeposit_gen[0])\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTftFOhSmDMg",
        "colab_type": "text"
      },
      "source": [
        "## Calculate PRD score between these batch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWEusQu0mDMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Regressor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Regressor, self).__init__()\n",
        "        self.batchnorm0 = nn.BatchNorm2d(1)\n",
        "        self.conv1 = nn.Conv2d(1, 16, 2, stride=2)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 2, stride=2)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 2, stride=2)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 2)\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        \n",
        "        self.fc1 = nn.Linear(256, 256) \n",
        "        self.batchnorm4 = nn.BatchNorm1d(256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 2 + 3)\n",
        "        self.fc5 = nn.Linear(64, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.batchnorm0(self.dropout(x))\n",
        "        x = self.batchnorm1(self.dropout(F.relu(self.conv1(x))))\n",
        "        x = self.batchnorm2(F.relu(self.conv2(x)))\n",
        "        x = self.batchnorm3(F.relu(self.conv3(x)))\n",
        "        x = F.relu(self.conv4(x)) # 64, 5, 5\n",
        "        x = x.view(len(x), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.batchnorm4(self.dropout(F.relu(self.fc1(x))))\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        x = torch.tanh(self.fc3(x))\n",
        "        return self.fc4(x), self.fc5(x)\n",
        "    \n",
        "    def get_encoding(self, x):\n",
        "        x = self.batchnorm0(self.dropout(x))\n",
        "        x = self.batchnorm1(self.dropout(F.relu(self.conv1(x))))\n",
        "        x = self.batchnorm2(F.relu(self.conv2(x)))\n",
        "        x = self.batchnorm3(F.relu(self.conv3(x)))\n",
        "        x = F.relu(self.conv4(x)) # 64, 5, 5\n",
        "        x = x.view(len(x), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.batchnorm4(self.dropout(F.relu(self.fc1(x))))\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "    \n",
        "\n",
        "def load_embedder(path):\n",
        "    embedder = torch.load(path)\n",
        "    embedder.eval()\n",
        "    return embedder\n",
        "\n",
        "embedder = load_embedder('./embedder.tp')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd63IOwVmDMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_real = embedder.get_encoding(torch.tensor(EnergyDeposit).float().view(-1, 1, 30, 30)).detach().numpy()\n",
        "data_fake = embedder.get_encoding(torch.tensor(EnergyDeposit_gen).float().view(-1, 1, 30, 30)).detach().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGM2uI_qmDMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_pr_aucs(precisions, recalls):\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    pr_aucs = []\n",
        "    for i in range(len(recalls)):\n",
        "        plt.step(recalls[i], precisions[i], color='b', alpha=0.2,  label='PR-AUC={}'.format(auc(precisions[i], recalls[i])))\n",
        "        pr_aucs.append(auc(precisions[i], recalls[i]))\n",
        "    plt.step(np.mean(recalls, axis=0), np.mean(precisions, axis=0), color='r', alpha=1,  label='average')\n",
        "    plt.fill_between(np.mean(recalls, axis=0), \n",
        "                     np.mean(precisions, axis=0) - np.std(precisions, axis=0) * 3,\n",
        "                     np.mean(precisions, axis=0) + np.std(precisions, axis=0) * 3, color='g', alpha=0.2,  label='std')\n",
        "\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "\n",
        "    # plt.ylim([0.0, 1.05])\n",
        "    # plt.xlim([0.0, 1.0])\n",
        "    print(np.mean(pr_aucs), np.std(pr_aucs))\n",
        "    plt.legend()\n",
        "    \n",
        "    return pr_aucs\n",
        "\n",
        "def calc_pr_rec(data_real, data_fake, num_clusters=20, num_runs=10, NUM_RUNS=10):\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    for i in tqdm(range(NUM_RUNS)):\n",
        "        precision, recall = compute_prd_from_embedding(data_real, data_fake, num_clusters=num_clusters, num_runs=num_runs)\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "    return precisions, recalls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NApjdKVmDMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "precisions, recalls = calc_pr_rec(data_real, data_fake, num_clusters=100, num_runs=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0D4-j__mDMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_aucs = plot_pr_aucs(precisions, recalls)\n",
        "plt.title('Num_clusters={}, num_runs={}, first third'.format(100, 20))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erF_MpJ_mDMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_aucs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXkiQuGlmDMs",
        "colab_type": "text"
      },
      "source": [
        "## Physical metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI_33EaxmDMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.lines as mlines\n",
        "def newline(p1, p2):\n",
        "    ax = plt.gca()\n",
        "    xmin, xmax = ax.get_xbound()\n",
        "\n",
        "    if(p2[0] == p1[0]):\n",
        "        xmin = xmax = p1[0]\n",
        "        ymin, ymax = ax.get_ybound()\n",
        "    else:\n",
        "        ymax = p1[1]+(p2[1]-p1[1])/(p2[0]-p1[0])*(xmax-p1[0])\n",
        "        ymin = p1[1]+(p2[1]-p1[1])/(p2[0]-p1[0])*(xmin-p1[0])\n",
        "\n",
        "    l = mlines.Line2D([xmin,xmax], [ymin,ymax])\n",
        "    ax.add_line(l)\n",
        "    return l\n",
        "\n",
        "def plot_axes_for_shower(ecal, point, p):\n",
        "    x = np.linspace(-14.5, 14.5, 30)\n",
        "    y = np.linspace(-14.5, 14.5, 30)\n",
        "\n",
        "    xx, yy = np.meshgrid(x, y)\n",
        "    zoff = 25.\n",
        "    ipic = 3\n",
        "    orth = np.array([-p[1], p[0]])\n",
        "\n",
        "    pref = point[:2] + p[:2] * zoff / p[2]\n",
        "\n",
        "    p1 = pref - 10 * p[:2]\n",
        "    p2 = pref + 10 * p[:2]\n",
        "    p3 = pref - 10 * orth\n",
        "    p4 = pref + 10 * orth\n",
        "\n",
        "    plt.contourf(xx, yy, np.log(ecal + 1), cmap=plt.cm.inferno)\n",
        "    newline(p1, p2)\n",
        "    newline(p3, p4)\n",
        "    plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR08nJ9gmDMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = 2\n",
        "plot_axes_for_shower(EnergyDeposit[idx], point=ParticlePoint[idx].detach().numpy(),\n",
        "                     p=ParticleMomentum[idx].detach().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUCqH0_SmDMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from calogan_metrics import get_assymetry, get_shower_width, get_sparsity_level"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbvzfsYUmDM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assym = get_assymetry(EnergyDeposit, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy(), orthog=False)\n",
        "assym_ortho = get_assymetry(EnergyDeposit, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy(), orthog=True)\n",
        "sh_width = get_shower_width(EnergyDeposit, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy(), orthog=False)\n",
        "sh_width_ortho = get_shower_width(EnergyDeposit, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy(), orthog=True)\n",
        "sparsity_level = get_sparsity_level(EnergyDeposit)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eJLvn3EmDM2",
        "colab_type": "text"
      },
      "source": [
        "## Longitudual cluster asymmetry"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEORbnE7mDM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set(font_scale=2)\n",
        "plt.hist(assym, bins=50, range=[-1, 1], color='red', alpha=0.3, normed=True, label='MC');\n",
        "plt.xlabel('Longitudual cluster asymmetry')\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15wFghYcmDM3",
        "colab_type": "text"
      },
      "source": [
        "## Transverse cluster asymmetry"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfge5LTMmDM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set(font_scale=2)\n",
        "plt.hist(assym_ortho, bins=50, range=[-1, 1], color='red', alpha=0.3, normed=True, label='MC');\n",
        "plt.xlabel('Transverse cluster asymmetry')\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4lWh8VAmDM5",
        "colab_type": "text"
      },
      "source": [
        "## Cluster longitudual width"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB27rAtImDM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(sh_width, bins=50, range=[0, 15], normed=True, alpha=0.3, color='red', label='MC');\n",
        "plt.title('Shower longitudial width')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('Cluster longitudual width [cm]')\n",
        "plt.ylabel('Arbitrary units')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC-HiFBamDM7",
        "colab_type": "text"
      },
      "source": [
        "## Cluster trasverse width"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBIu8gwLmDM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(sh_width_ortho, bins=50, range=[0,10], normed=True, alpha=0.3, color='blue', label='MC');\n",
        "#plt.title('Shower transverse width')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('Cluster trasverse width [cm]')\n",
        "plt.ylabel('Arbitrary units')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pFbBYvOmDNA",
        "colab_type": "text"
      },
      "source": [
        "## Sparsity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob53fPO_mDNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alphas = np.log(np.logspace(-5, -1, 20))\n",
        "means_r = np.mean(sparsity_level, axis=1)\n",
        "stddev_r = np.std(sparsity_level, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QygKaRldmDNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(alphas, means_r, color='red')\n",
        "plt.fill_between(alphas, means_r-stddev_r, means_r+stddev_r, color='red', alpha=0.3)\n",
        "plt.legend(['MC'])\n",
        "plt.title('Sparsity')\n",
        "plt.xlabel('log10(Threshold/GeV)')\n",
        "plt.ylabel('Fraction of cells above threshold')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-imUBMEmDND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from calogan_metrics import get_physical_stats\n",
        "real_phys_stats = get_physical_stats(EnergyDeposit, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy())\n",
        "gen_phys_stats = get_physical_stats(EnergyDeposit_gen, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp_s9vGcmDNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "precisions, recalls = calc_pr_rec(real_phys_stats, gen_phys_stats, num_clusters=100, num_runs=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btvs99JKmDNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_aucs = plot_pr_aucs(precisions, recalls)\n",
        "plt.title('Num_clusters={}, num_runs={}, first third'.format(100, 20))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOyBgN-4mDNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_aucs"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}