{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bayesian_lhcb_calo_gan.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satoruk-icepp/mlhep2019_2_phase/blob/master/Bayesian_lhcb_calo_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud8PAMb2mDK9",
        "colab_type": "code",
        "outputId": "d0ef0581-88fa-4ccf-a631-753ad168e43f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "! wget https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/calogan_metrics.py\n",
        "! wget https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/prd_score.py\n",
        "! wget https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/score.py\n",
        "! wget https://github.com/SchattenGenie/mlhep2019_2_phase/raw/master/analysis/embedder.tp\n",
        "! wget https://github.com/SchattenGenie/mlhep2019_2_phase/raw/master/analysis/generator.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-13 18:50:57--  https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/calogan_metrics.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4115 (4.0K) [text/plain]\n",
            "Saving to: ‘calogan_metrics.py.1’\n",
            "\n",
            "\rcalogan_metrics.py.   0%[                    ]       0  --.-KB/s               \rcalogan_metrics.py. 100%[===================>]   4.02K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-07-13 18:50:57 (105 MB/s) - ‘calogan_metrics.py.1’ saved [4115/4115]\n",
            "\n",
            "--2019-07-13 18:50:59--  https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/prd_score.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12426 (12K) [text/plain]\n",
            "Saving to: ‘prd_score.py.1’\n",
            "\n",
            "prd_score.py.1      100%[===================>]  12.13K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-07-13 18:50:59 (140 MB/s) - ‘prd_score.py.1’ saved [12426/12426]\n",
            "\n",
            "--2019-07-13 18:51:00--  https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/score.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7642 (7.5K) [text/plain]\n",
            "Saving to: ‘score.py.1’\n",
            "\n",
            "score.py.1          100%[===================>]   7.46K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-07-13 18:51:01 (116 MB/s) - ‘score.py.1’ saved [7642/7642]\n",
            "\n",
            "--2019-07-13 18:51:02--  https://github.com/SchattenGenie/mlhep2019_2_phase/raw/master/analysis/embedder.tp\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/embedder.tp [following]\n",
            "--2019-07-13 18:51:02--  https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/embedder.tp\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 569697 (556K) [application/octet-stream]\n",
            "Saving to: ‘embedder.tp.1’\n",
            "\n",
            "embedder.tp.1       100%[===================>] 556.34K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-07-13 18:51:02 (10.5 MB/s) - ‘embedder.tp.1’ saved [569697/569697]\n",
            "\n",
            "--2019-07-13 18:51:03--  https://github.com/SchattenGenie/mlhep2019_2_phase/raw/master/analysis/generator.py\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/generator.py [following]\n",
            "--2019-07-13 18:51:04--  https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/generator.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1514 (1.5K) [text/plain]\n",
            "Saving to: ‘generator.py.1’\n",
            "\n",
            "generator.py.1      100%[===================>]   1.48K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-07-13 18:51:04 (194 MB/s) - ‘generator.py.1’ saved [1514/1514]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "790_h5rSmDLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as utils\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "sns.set()\n",
        "\n",
        "def one_hot(a, num_classes):\n",
        "    return np.squeeze(np.eye(num_classes)[a.reshape(-1)])\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW0lyRVGmDLC",
        "colab_type": "code",
        "outputId": "b5591112-6b88-4302-fe1a-7d37ef11656d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giyM_o8bmDLI",
        "colab_type": "code",
        "outputId": "9d2e290d-19ed-4cb1-84d1-1f470668e1b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJbcY6IwmDLK",
        "colab_type": "text"
      },
      "source": [
        "## Data pathes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5muy7MJmDLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_path = '/gdrive/My Drive/mlhep2019_gan/data_train.npz'\n",
        "val_data_path = '/gdrive/My Drive/mlhep2019_gan/data_val.npz'\n",
        "test_data_path = '/gdrive/My Drive/mlhep2019_gan/data_test.npz'\n",
        "\n",
        "# train_data_path = '../data_train.npz'\n",
        "# val_data_path = '../data_val.npz'\n",
        "# test_data_path = '../data_test.npz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqklR3OHmDLM",
        "colab_type": "text"
      },
      "source": [
        "# Loading data\n",
        "\n",
        "Data is stored in `.npz`-format which is a special filetype for persisting multiple NumPy arrays on disk. \n",
        "\n",
        "More info: https://docs.scipy.org/doc/numpy/reference/generated/numpy.lib.format.html#module-numpy.lib.format.\n",
        "\n",
        "File `dat_train.npz` contains four arrays: \n",
        "\n",
        "  * `EnergyDeposit` - images of calorimeters responses\n",
        "  * `ParticleMomentum` - $p_x, p_y, p_z$ of initial partice\n",
        "  * `ParticlePoint` - $x, y$ of initial particle\n",
        "  * `ParticlePDG` - particle type(either $e^-$ or $\\gamma$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcLIRNvMmDLN",
        "colab_type": "code",
        "outputId": "a2fcfa97-0911-4ee2-8bc3-d11ebfbb1e41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# N = 1000\n",
        "\n",
        "data_train = np.load(train_data_path, allow_pickle=True)\n",
        "print(list(data_train.keys()))\n",
        "# N = len(data_train)\n",
        "N=50250\n",
        "# [data_size, 900]\n",
        "EnergyDeposit = data_train['EnergyDeposit'][:N]\n",
        "# reshaping it as [data_size, channels, img_size_x, img_size_y]\n",
        "# channels are needed for pytorch conv2d-layers\n",
        "EnergyDeposit = EnergyDeposit.reshape(-1, 1, 30, 30)\n",
        "\n",
        "# [data_size, 3]\n",
        "ParticleMomentum = data_train['ParticleMomentum'][:N]\n",
        "\n",
        "# [data_size, 2]\n",
        "ParticlePoint = data_train['ParticlePoint'][:, :2][:N]\n",
        "\n",
        "# [data_size, 1]\n",
        "ParticlePDG = data_train['ParticlePDG'][:N]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['EnergyDeposit', 'ParticlePoint', 'ParticleMomentum', 'ParticlePDG']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExAROHySmDLP",
        "colab_type": "text"
      },
      "source": [
        "## Load it to pytorch `DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtEr15sdmDLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EnergyDeposit = torch.tensor(EnergyDeposit).float()\n",
        "ParticleMomentum = torch.tensor(ParticleMomentum).float()\n",
        "ParticlePoint = torch.tensor(ParticlePoint).float()\n",
        "\n",
        "BATCH_SIZE = 150\n",
        "calo_dataset = utils.TensorDataset(EnergyDeposit, ParticleMomentum, ParticlePoint)\n",
        "calo_dataloader = torch.utils.data.DataLoader(calo_dataset, batch_size=BATCH_SIZE, pin_memory=True, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crC_kDGkmDLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b in calo_dataloader:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inm6pj7DmDLU",
        "colab_type": "text"
      },
      "source": [
        "## Training GAN\n",
        "###### ...is not a simple matter\n",
        "\n",
        "It depends on architecture, loss, instance noise, augmentation and even luck(recommend to take a look https://arxiv.org/pdf/1801.04406.pdf)\n",
        "\n",
        "\n",
        "In this notebook I have prepared some basic parts that you could use for your experiments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU8Gxli9mDLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TASKS = ['KL', 'REVERSED_KL', 'WASSERSTEIN', 'BAYESIAN']\n",
        "\n",
        "TASK = 'BAYESIAN'\n",
        "# TASK = 'WASSERSTEIN'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hglQBy1U2cn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.0002\n",
        "dnoise_alpha = 0.0001\n",
        "gnoise_alpha = 0.0001\n",
        "LATENT_DIM = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99KKDCxvmDLY",
        "colab_type": "text"
      },
      "source": [
        "### Additional things for Wasserstein GAN\n",
        "\n",
        "To make `Wasserstein`-GAN works we suggest three options:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0_bjx8ZmDLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIPSITZ_WEIGHTS = False\n",
        "clamp_lower, clamp_upper = -0.01, 0.01\n",
        "\n",
        "\n",
        "# https://arxiv.org/abs/1704.00028\n",
        "GRAD_PENALTY = True\n",
        "\n",
        "# https://arxiv.org/abs/1705.09367\n",
        "ZERO_CENTERED_GRAD_PENALTY = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNKTOTNkmDLb",
        "colab_type": "text"
      },
      "source": [
        "#### Small hack that can speed-up training and improve generalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOq11rptmDLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://arxiv.org/abs/1610.04490\n",
        "INSTANCE_NOISE = True\n",
        "\n",
        "def add_instance_noise(data, std=0.01):\n",
        "    return data + torch.distributions.Normal(0, std).sample(data.shape).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXxWCTIymDLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GANLosses(object):\n",
        "    def __init__(self, task, device):\n",
        "        self.TASK = task\n",
        "        self.device = device\n",
        "    \n",
        "    def g_loss(self, discrim_output):\n",
        "        eps = 1e-10\n",
        "        if self.TASK == 'KL': \n",
        "            loss = torch.log(1 - discrim_output + eps).mean()    \n",
        "        elif self.TASK == 'REVERSED_KL':\n",
        "            loss = - torch.log(discrim_output + eps).mean()\n",
        "        elif self.TASK == 'WASSERSTEIN':\n",
        "            loss = - discrim_output.mean()\n",
        "        return loss\n",
        "\n",
        "    def d_loss(self, discrim_output_gen, discrim_output_real):\n",
        "        eps = 1e-10\n",
        "        if self.TASK in ['KL', 'REVERSED_KL']: \n",
        "            loss = - torch.log(discrim_output_real + eps).mean() - torch.log(1 - discrim_output_gen + eps).mean()\n",
        "        elif self.TASK == 'WASSERSTEIN':\n",
        "            loss = - (discrim_output_real.mean() - discrim_output_gen.mean())\n",
        "        return loss\n",
        "\n",
        "    def calc_gradient_penalty(self, discriminator, data_gen, inputs_batch, inp_data, lambda_reg = .1):\n",
        "        alpha = torch.rand(inp_data.shape[0], 1).to(self.device)\n",
        "        dims_to_add = len(inp_data.size()) - 2\n",
        "        for i in range(dims_to_add):\n",
        "            alpha = alpha.unsqueeze(-1)\n",
        "        # alpha = alpha.expand(inp_data.size())\n",
        "\n",
        "        interpolates = (alpha * inp_data + ((1 - alpha) * data_gen)).to(self.device)\n",
        "\n",
        "        interpolates.requires_grad = True\n",
        "\n",
        "        disc_interpolates = discriminator(interpolates, inputs_batch)\n",
        "\n",
        "        gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
        "                                        grad_outputs=torch.ones(disc_interpolates.size()).to(self.device),\n",
        "                                        create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "\n",
        "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * lambda_reg\n",
        "        return gradient_penalty\n",
        "    \n",
        "    def calc_zero_centered_GP(self, discriminator, data_gen, inputs_batch, inp_data, gamma_reg = .1):\n",
        "        \n",
        "        local_input = inp_data.clone().detach().requires_grad_(True)\n",
        "        disc_interpolates = discriminator(local_input, inputs_batch)\n",
        "        gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=local_input,\n",
        "                                        grad_outputs=torch.ones(disc_interpolates.size()).to(self.device),\n",
        "                                        create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "        return gamma_reg / 2 * (gradients.norm(2, dim=1) ** 2).mean() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYW8x_ln2OFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _assert_no_grad(variable):\n",
        "    assert not variable.requires_grad, \\\n",
        "        \"nn criterions don't compute the gradient w.r.t. targets - please \" \\\n",
        "        \"mark these variables as volatile or not requiring gradients\"\n",
        "\n",
        "class ComplementCrossEntropyLoss(torch.nn.Module):\n",
        "  # Note: This is the cross entropy of the sum of all probabilities of other indices, except for the \n",
        "  # This is used in Bayesian GAN semi-supervised learning\n",
        "    def __init__(self, except_index=None, weight=None, ignore_index=-100, size_average=True, reduce=True):\n",
        "        super(ComplementCrossEntropyLoss, self).__init__()\n",
        "        self.except_index = except_index\n",
        "        self.weight = weight\n",
        "        self.ignore_index = ignore_index\n",
        "        self.size_average = size_average\n",
        "        self.reduce = reduce\n",
        "\n",
        "    def forward(self, input, target=None):\n",
        "    # Use target if not None, else use self.except_index\n",
        "        if target is not None:\n",
        "            _assert_no_grad(target)\n",
        "        else:\n",
        "            assert self.except_index is not None\n",
        "            target = torch.autograd.Variable(torch.LongTensor(input.data.shape[0]).fill_(self.except_index).cuda())\n",
        "            result = torch.nn.functional.nll_loss(\n",
        "            torch.log(1. - torch.nn.functional.softmax(input) + 1e-4), \n",
        "            target, weight=self.weight, \n",
        "            size_average=self.size_average, \n",
        "            ignore_index=self.ignore_index)\n",
        "        return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWQqgdmQ2QDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "#from distributions import Normal\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class NoiseLoss(torch.nn.Module):\n",
        "  # need the scale for noise standard deviation\n",
        "  # scale = noise  std\n",
        "    def __init__(self, params, scale=None, observed=None):\n",
        "        super(NoiseLoss, self).__init__()\n",
        "        # initialize the distribution for each parameter\n",
        "        #self.distributions = []\n",
        "        self.noises = []\n",
        "        for param in params:\n",
        "            noise = 0*param.data.cuda() # will fill with normal at each forward\n",
        "            self.noises.append(noise)\n",
        "        if scale is not None:\n",
        "            self.scale = scale\n",
        "        else:\n",
        "            self.scale = 1.\n",
        "        self.observed = observed\n",
        "\n",
        "    def forward(self, params, scale=None, observed=None):\n",
        "    # scale should be sqrt(2*alpha/eta)\n",
        "    # where eta is the learning rate and alpha is the strength of drag term\n",
        "        if scale is None:\n",
        "            scale = self.scale\n",
        "        if observed is None:\n",
        "            observed = self.observed\n",
        "\n",
        "        assert scale is not None, \"Please provide scale\"\n",
        "        noise_loss = 0.0\n",
        "        for noise, var in zip(self.noises, params):\n",
        "            # This is scale * z^T*v\n",
        "            # The derivative wrt v will become scale*z\n",
        "            _noise = noise.normal_(0,1)\n",
        "#             print(_noise.shape,var.shape)\n",
        "#             print(torch.sum(Variable(_noise)*var))\n",
        "            noise_loss += scale*torch.sum(Variable(_noise)*var)\n",
        "        noise_loss /= observed\n",
        "        return noise_loss\n",
        "\n",
        "class PriorLoss(torch.nn.Module):\n",
        "  # negative log Gaussian prior\n",
        "    def __init__(self, prior_std=1., observed=None):\n",
        "        super(PriorLoss, self).__init__()\n",
        "        self.observed = observed\n",
        "        self.prior_std = prior_std\n",
        "\n",
        "    def forward(self, params, observed=None):\n",
        "        if observed is None:\n",
        "            observed = self.observed\n",
        "        prior_loss = 0.0\n",
        "        for var in params:\n",
        "#             print(var.shape,self.prior_std)\n",
        "#             print(var*var)\n",
        "            prior_loss += torch.sum(var*var/(self.prior_std*self.prior_std))\n",
        "#             prior_loss += torch.sum((var**2)/(self.prior_std**2))\n",
        "#             prior_loss += torch.sum(var.pow(2)/(self.prior_std**2))\n",
        "        prior_loss /= observed\n",
        "        return prior_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA5ResSp2WXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "# use the default index = 0 - equivalent to summing all other probabilities\n",
        "criterion_comp = ComplementCrossEntropyLoss(except_index=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT8YWKN5mDLg",
        "colab_type": "text"
      },
      "source": [
        "## Defining discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skiem1EXmDLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelD, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
        "        self.bn3 = nn.BatchNorm2d(64)        \n",
        "        self.conv4 = nn.Conv2d(64, 64, 2)\n",
        "        self.conv5 = nn.Conv2d(64, 32, 2)        \n",
        "        \n",
        "        # size\n",
        "        self.fc1 = nn.Linear(2592 + 5, 1024) \n",
        "        self.fc2 = nn.Linear(1024, 512)         \n",
        "        self.fc3 = nn.Linear(512, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 2)\n",
        "        \n",
        "    def forward(self, EnergyDeposit, ParticleMomentum_ParticlePoint):\n",
        "        EnergyDeposit = self.dropout(F.leaky_relu(self.bn1(self.conv1(EnergyDeposit))))\n",
        "        EnergyDeposit = self.dropout(F.leaky_relu(self.bn2(self.conv2(EnergyDeposit))))\n",
        "#         EnergyDeposit = self.dropout(F.leaky_relu(self.conv1(EnergyDeposit)))\n",
        "#         EnergyDeposit = self.dropout(F.leaky_relu(self.conv2(EnergyDeposit)))\n",
        "        EnergyDeposit = F.leaky_relu(self.bn3(self.conv3(EnergyDeposit)))\n",
        "        EnergyDeposit = F.leaky_relu(self.conv4(EnergyDeposit)) # 32, 9, 9\n",
        "        EnergyDeposit = F.leaky_relu(self.conv5(EnergyDeposit)) # 32, 9, 9        \n",
        "        EnergyDeposit = EnergyDeposit.view(len(EnergyDeposit), -1)\n",
        "        \n",
        "        t = torch.cat([EnergyDeposit, ParticleMomentum_ParticlePoint], dim=1)\n",
        "        \n",
        "        t = F.leaky_relu(self.fc1(t))\n",
        "        t = F.leaky_relu(self.fc2(t))\n",
        "        t = F.leaky_relu(self.fc3(t))\n",
        "        t = F.leaky_relu(self.fc4(t))\n",
        "        if TASK == 'WASSERSTEIN' or TASK == 'BAYESIAN':\n",
        "            return self.fc5(t)\n",
        "        else:\n",
        "            return torch.sigmoid(self.fc5(t))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4_WffK-mDLi",
        "colab_type": "text"
      },
      "source": [
        "## Defining generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15gNgQ-ymDLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from generator import ModelGConvTranspose, NOISE_DIM\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "NOISE_DIM = 10\n",
        "\n",
        "class ModelGConvTranspose(nn.Module):\n",
        "    def __init__(self, z_dim):\n",
        "        self.z_dim = z_dim\n",
        "        super(ModelGConvTranspose, self).__init__()\n",
        "        self.fc1 = nn.Linear(self.z_dim + 2 + 3, 64)\n",
        "        self.fc2 = nn.Linear(64, 128)\n",
        "        self.fc3 = nn.Linear(128, 512)\n",
        "        self.fc4 = nn.Linear(512, 20736)\n",
        "        \n",
        "        self.conv1 = nn.ConvTranspose2d(256, 256, 3, stride=2, output_padding=1)\n",
        "        self.conv2 = nn.ConvTranspose2d(256, 128, 3)\n",
        "        self.conv3 = nn.ConvTranspose2d(128, 64, 3)\n",
        "        self.conv4 = nn.ConvTranspose2d(64, 32, 3)\n",
        "        self.conv5 = nn.ConvTranspose2d(32, 32, 2)\n",
        "        self.conv6 = nn.ConvTranspose2d(32, 16, 2)\n",
        "        self.conv7 = nn.ConvTranspose2d(16, 16, 2)        \n",
        "        self.conv8 = nn.ConvTranspose2d(16, 1, 3)\n",
        "        \n",
        "        \n",
        "    def forward(self, z, ParticleMomentum_ParticlePoint):\n",
        "        x = F.leaky_relu(self.fc1(\n",
        "            torch.cat([z, ParticleMomentum_ParticlePoint], dim=1)\n",
        "        ))\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        x = F.leaky_relu(self.fc3(x))\n",
        "        x = F.leaky_relu(self.fc4(x))\n",
        "        \n",
        "        EnergyDeposit = x.view(-1, 256, 9, 9)\n",
        "        \n",
        "        EnergyDeposit = F.leaky_relu(self.conv1(EnergyDeposit))\n",
        "        EnergyDeposit = F.leaky_relu(self.conv2(EnergyDeposit))\n",
        "        EnergyDeposit = F.leaky_relu(self.conv3(EnergyDeposit))\n",
        "        EnergyDeposit = F.leaky_relu(self.conv4(EnergyDeposit))\n",
        "        EnergyDeposit = F.leaky_relu(self.conv5(EnergyDeposit))\n",
        "        EnergyDeposit = F.leaky_relu(self.conv6(EnergyDeposit))        \n",
        "#         EnergyDeposit = F.leaky_relu(self.conv7(EnergyDeposit))                \n",
        "        EnergyDeposit = self.conv8(EnergyDeposit)\n",
        "\n",
        "        return EnergyDeposit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys1Z545TmDLl",
        "colab_type": "text"
      },
      "source": [
        "## Check our models on one batch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe748y6nmDLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "disc = ModelD().to(device)\n",
        "gens = []\n",
        "for i in range(10):\n",
        "    gen = ModelGConvTranspose(z_dim=NOISE_DIM).to(device)\n",
        "    gens.append(gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUk-rAs1mDLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b = EnergyDeposit_b.to(device), \\\n",
        "                                                       ParticleMomentum_b.to(device), \\\n",
        "                                                       ParticlePoint_b.to(device)\n",
        "ParticleMomentum_ParticlePoint_b = torch.cat([ParticleMomentum_b.to(device), ParticlePoint_b.to(device)], dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxV-qa2YmDLq",
        "colab_type": "code",
        "outputId": "59898355-ab85-42f8-db2c-bb47c360d764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "EnergyDeposit_b.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([150, 1, 30, 30])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcrCO7wRmDLv",
        "colab_type": "code",
        "outputId": "623704f0-5c96-443d-fef3-4739f27f87ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "disc(EnergyDeposit_b, ParticleMomentum_ParticlePoint_b).shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([150, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxagWRP6mDLx",
        "colab_type": "code",
        "outputId": "d241ca58-8aee-4b8f-9961-0b1c3c4ed519",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "noise = torch.randn(len(EnergyDeposit_b), NOISE_DIM).to(device)\n",
        "gens[0](noise, ParticleMomentum_ParticlePoint_b).shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([150, 1, 30, 30])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgnGKjGF4MPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "gprior_criterion = PriorLoss(prior_std=1., observed=10000.)\n",
        "gnoise_criterion = NoiseLoss(params=gens[0].parameters(), scale=math.sqrt(2*gnoise_alpha/learning_rate), observed=10000.)\n",
        "dprior_criterion = PriorLoss(prior_std=1., observed=10000.)\n",
        "dnoise_criterion = NoiseLoss(params=disc.parameters(), scale=math.sqrt(2*dnoise_alpha*learning_rate), observed=10000.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCaPksu4mDLz",
        "colab_type": "text"
      },
      "source": [
        "## Defining optimiser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXVckXSZmDL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learning_rate_dis = 1e-5\n",
        "# learning_rate_gen = 1e-5\n",
        "gens_opt = []\n",
        "for gen in gens:\n",
        "    gen_opt = optim.Adam(gen.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
        "    gens_opt.append(gen_opt)\n",
        "# gen_opt = optim.Adam(gen.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
        "# g_optimizer = optim.RMSprop(discriminator.parameters(), lr=learning_rate_dis, weight_decay=1e-6)\n",
        "# d_optimizer = optim.SGD(discriminator.parameters(), lr=learning_rate_dis, weight_decay=1e-6)\n",
        "# d_optimizer = optim.RMSprop(discriminator.parameters(), lr=learning_rate_dis, weight_decay=1e-6)\n",
        "disc_opt = optim.Adam(disc.parameters(), lr=learning_rate, betas=(0.5, 0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpBbUF9DmDL2",
        "colab_type": "text"
      },
      "source": [
        "## Load scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9v-IZO8mDL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from prd_score import compute_prd, compute_prd_from_embedding, _prd_to_f_beta\n",
        "from sklearn.metrics import auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c18oWujomDL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def run_training(epochs):\n",
        "\n",
        "    # ===========================\n",
        "    # IMPORTANT PARAMETER:\n",
        "    # Number of D updates per G update\n",
        "    # ===========================\n",
        "    k_d, k_g = 1, 1\n",
        "\n",
        "    gan_losses = GANLosses(TASK, device)\n",
        "    dis_epoch_loss = []\n",
        "    gen_epoch_loss = []\n",
        "    predictions_dis = []\n",
        "    predictions_gen = []\n",
        "    prd_auc = []  \n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        first = True\n",
        "        \n",
        "        for EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b in calo_dataloader:\n",
        "            EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b = EnergyDeposit_b.to(device), \\\n",
        "                                                                   ParticleMomentum_b.to(device), \\\n",
        "                                                                   ParticlePoint_b.to(device)\n",
        "            ParticleMomentum_ParticlePoint_b = torch.cat([ParticleMomentum_b.to(device), ParticlePoint_b.to(device)], dim=1)\n",
        "            output = disc(EnergyDeposit_b,ParticleMomentum_ParticlePoint_b)\n",
        "            disc_real = criterion_comp(output)\n",
        "            disc_real.backward()\n",
        "            EnergyDeposit_gens = []\n",
        "            ParticleMomentum_ParticlePoint_bs = []\n",
        "            for gen in gens:\n",
        "                noise = torch.randn(len(EnergyDeposit_b), NOISE_DIM).to(device)\n",
        "                EnergyDeposit_gen = gen(noise, ParticleMomentum_ParticlePoint_b)\n",
        "                EnergyDeposit_gens.append(EnergyDeposit_gen)\n",
        "                ParticleMomentum_ParticlePoint_bs.append(ParticleMomentum_ParticlePoint_b)\n",
        "            EnergyDeposit_gens = torch.cat(EnergyDeposit_gens)\n",
        "            ParticleMomentum_ParticlePoint_bs = torch.cat(ParticleMomentum_ParticlePoint_bs)\n",
        "\n",
        "            output = disc(EnergyDeposit_gens.detach(),ParticleMomentum_ParticlePoint_bs)\n",
        "            labelv_fake = Variable(torch.LongTensor(EnergyDeposit_gens.data.shape[0]).cuda().fill_(0))\n",
        "            disc_fake = criterion(output, labelv_fake.cuda())\n",
        "            disc_fake.backward()\n",
        "            \n",
        "            output = disc(EnergyDeposit_b.detach(),ParticleMomentum_ParticlePoint_b)\n",
        "            labelv_real = Variable(torch.LongTensor(EnergyDeposit_b.data.shape[0]).cuda().fill_(1))\n",
        "            err_sup = criterion(output, labelv_real.cuda())\n",
        "            err_sup.backward()\n",
        "            disc_prior = dprior_criterion(disc.parameters())\n",
        "            disc_prior.backward()\n",
        "            disc_noise = dnoise_criterion(disc.parameters())\n",
        "            disc_noise.backward()\n",
        "            disc_loss = disc_real + disc_fake + err_sup + disc_prior + disc_noise\n",
        "            dis_epoch_loss.append(disc_loss.item())\n",
        "            predictions_dis.append(\n",
        "                list(disc(EnergyDeposit_b, ParticleMomentum_ParticlePoint_b).detach().cpu().numpy().ravel())\n",
        "            )\n",
        "\n",
        "            predictions_gen.append(\n",
        "                list(disc(EnergyDeposit_gen, ParticleMomentum_ParticlePoint_b).detach().cpu().numpy().ravel())\n",
        "            )\n",
        "            \n",
        "            disc_opt.step()\n",
        "            for gen_opt in gens_opt:\n",
        "                gen_opt.zero_grad()\n",
        "            output = disc(EnergyDeposit_gens,ParticleMomentum_ParticlePoint_bs)\n",
        "            gen_loss = criterion_comp(output)\n",
        "            for gen in gens:\n",
        "                gen_loss += gprior_criterion(gen.parameters())\n",
        "                gen_loss += gnoise_criterion(gen.parameters())    \n",
        "            gen_loss.backward()\n",
        "            for gen_opt in gens_opt:\n",
        "                gen_opt.step()\n",
        "            gen_epoch_loss.append(gen_loss.item())\n",
        "            EnergyDeposit_gen_sample = EnergyDeposit_gens                    \n",
        "            EnergyDeposit_dat_sample = EnergyDeposit_b\n",
        "            if first:\n",
        "\n",
        "                precision, recall = compute_prd_from_embedding(\n",
        "                    EnergyDeposit_gen.detach().cpu().numpy().reshape(BATCH_SIZE, -1), \n",
        "                    EnergyDeposit_b.detach().cpu().numpy().reshape(BATCH_SIZE, -1),\n",
        "                    num_clusters=30,\n",
        "                    num_runs=100)\n",
        "                prd_auc.append(auc(precision, recall))\n",
        "                generator_cpu = ModelGConvTranspose(z_dim=NOISE_DIM)\n",
        "                generator_cpu.load_state_dict(gens[0].state_dict())\n",
        "#                 generator_cpu.eval()\n",
        "                torch.save(generator_cpu.state_dict(), './gan%d.pt'%(epoch))\n",
        "                first=False\n",
        "        \n",
        "            clear_output()\n",
        "            plt.figure(figsize=(15,12))\n",
        "            grid = plt.GridSpec(2, 3, wspace=0.4, hspace=0.3)\n",
        "            plt.subplot(grid[0,0])\n",
        "            plt.semilogy(dis_epoch_loss, label='dis_epoch_loss')\n",
        "            plt.semilogy(gen_epoch_loss, label='gen_epoch_loss')\n",
        "            plt.legend()\n",
        "\n",
        "            plt.subplot(grid[0,1])\n",
        "    #         plt.xlim(-1,2)\n",
        "            plt.hist(predictions_dis[-1], bins=40, label='dis_epoch_loss',color=\"blue\")\n",
        "            plt.hist(predictions_gen[-1], bins=40, label='gen_epoch_loss',color=\"orange\")\n",
        "            plt.legend()\n",
        "\n",
        "            plt.subplot(grid[0,2])\n",
        "            plt.plot(prd_auc, label='prd_auc')\n",
        "            plt.ylim(0,1)\n",
        "            plt.legend()\n",
        "    #         plt.show()\n",
        "\n",
        "            plt.subplot(grid[1, 0])\n",
        "            plt.imshow(EnergyDeposit_gen_sample[0][0].cpu().detach().numpy())\n",
        "            plt.subplot(grid[1, 1])\n",
        "            plt.imshow(EnergyDeposit_dat_sample[0][0].cpu().detach().numpy())\n",
        "            plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "zPLcnlKhmDMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run_training(200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT2fiNDMmDMJ",
        "colab_type": "text"
      },
      "source": [
        "#### Transfer generator on CPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTumKz8smDMK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "1ae61810-f2cc-4fc5-f1e2-71d493adf5f1"
      },
      "source": [
        "generator_cpu = ModelGConvTranspose(z_dim=NOISE_DIM)\n",
        "# generator_cpu.load_state_dict(generator.state_dict())\n",
        "generator_cpu.load_state_dict(torch.load('/gdrive/My Drive/gan12.pt'))\n",
        "generator_cpu.eval()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelGConvTranspose(\n",
              "  (fc1): Linear(in_features=15, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=512, bias=True)\n",
              "  (fc4): Linear(in_features=512, out_features=20736, bias=True)\n",
              "  (conv1): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), output_padding=(1, 1))\n",
              "  (conv2): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv3): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv4): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv5): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (conv6): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (conv7): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (conv8): ConvTranspose2d(16, 1, kernel_size=(3, 3), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrzMuZGzmDMM",
        "colab_type": "text"
      },
      "source": [
        "### Save model on disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXwtnaSBmDMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(generator_cpu.state_dict(), './gan.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nITR2bZwmDMO",
        "colab_type": "text"
      },
      "source": [
        "## Making predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihAqZQxvmDMP",
        "colab_type": "text"
      },
      "source": [
        "#### Validation predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "rVhVrubhmDMP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "183264af-64fb-4303-fbf2-1bd2a5c95d40"
      },
      "source": [
        "data_val = np.load(val_data_path, allow_pickle=True)\n",
        "ParticleMomentum_val = torch.tensor(data_val['ParticleMomentum']).float()\n",
        "ParticlePoint_val = torch.tensor(data_val['ParticlePoint'][:, :2]).float()\n",
        "ParticleMomentum_ParticlePoint_val = torch.cat([ParticleMomentum_val, ParticlePoint_val], dim=1)\n",
        "calo_dataset_val = utils.TensorDataset(ParticleMomentum_ParticlePoint_val)\n",
        "calo_dataloader_val = torch.utils.data.DataLoader(calo_dataset_val, batch_size=1024, shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    EnergyDeposit_val = []\n",
        "    for ParticleMomentum_ParticlePoint_val_batch in tqdm(calo_dataloader_val):\n",
        "        noise = torch.randn(len(ParticleMomentum_ParticlePoint_val_batch[0]), NOISE_DIM)\n",
        "        EnergyDeposit_val_batch = generator_cpu(noise, ParticleMomentum_ParticlePoint_val_batch[0]).detach().numpy()\n",
        "        EnergyDeposit_val.append(EnergyDeposit_val_batch)\n",
        "    np.savez_compressed('./data_val_prediction.npz', \n",
        "                        EnergyDeposit=np.concatenate(EnergyDeposit_val, axis=0).reshape(-1, 30, 30))\n",
        "\n",
        "    del EnergyDeposit_val\n",
        "del data_val; del ParticleMomentum_val; del ParticlePoint_val; del ParticleMomentum_ParticlePoint_val;\n",
        "del calo_dataset_val; calo_dataloader_val"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 5/50 [00:45<06:54,  9.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-6c5a2ba753b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mParticleMomentum_ParticlePoint_val_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalo_dataloader_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParticleMomentum_ParticlePoint_val_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNOISE_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mEnergyDeposit_val_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParticleMomentum_ParticlePoint_val_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mEnergyDeposit_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEnergyDeposit_val_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     np.savez_compressed('./data_val_prediction.npz', \n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-46287619dae6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z, ParticleMomentum_ParticlePoint)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mEnergyDeposit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEnergyDeposit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mEnergyDeposit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEnergyDeposit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mEnergyDeposit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEnergyDeposit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mEnergyDeposit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEnergyDeposit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    794\u001b[0m         return F.conv_transpose2d(\n\u001b[1;32m    795\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz2T9U3-mDMS",
        "colab_type": "text"
      },
      "source": [
        "#### Test predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "666U1Q_smDMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test = np.load(test_data_path, allow_pickle=True)\n",
        "ParticleMomentum_test = torch.tensor(data_test['ParticleMomentum']).float()\n",
        "ParticlePoint_test = torch.tensor(data_test['ParticlePoint'][:, :2]).float()\n",
        "ParticleMomentum_ParticlePoint_test = torch.cat([ParticleMomentum_test, ParticlePoint_test], dim=1)\n",
        "calo_dataset_test = utils.TensorDataset(ParticleMomentum_ParticlePoint_test)\n",
        "calo_dataloader_test = torch.utils.data.DataLoader(calo_dataset_test, batch_size=1024, shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    EnergyDeposit_test = []\n",
        "    for ParticleMomentum_ParticlePoint_test_batch in tqdm(calo_dataloader_test):\n",
        "        noise = torch.randn(len(ParticleMomentum_ParticlePoint_test_batch[0]), NOISE_DIM)\n",
        "        EnergyDeposit_test_batch = generator_cpu(noise, ParticleMomentum_ParticlePoint_test_batch[0]).detach().numpy()\n",
        "        EnergyDeposit_test.append(EnergyDeposit_test_batch)\n",
        "    np.savez_compressed('./data_test_prediction.npz', \n",
        "                        EnergyDeposit=np.concatenate(EnergyDeposit_test, axis=0).reshape(-1, 30, 30))\n",
        "\n",
        "    del EnergyDeposit_test\n",
        "del data_test; del ParticleMomentum_test; del ParticlePoint_test; del ParticleMomentum_ParticlePoint_test;\n",
        "del calo_dataset_test; calo_dataloader_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AIKCQMtmDMU",
        "colab_type": "text"
      },
      "source": [
        "## `zip-zip` files together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvbj0nhzmDMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip solution.zip data_val_prediction.npz data_test_prediction.npz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG-4EvGOmDMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import FileLink\n",
        "FileLink('./solution.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGp0K2LrmDMY",
        "colab_type": "text"
      },
      "source": [
        "# A few words about metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_j_38JamDMa",
        "colab_type": "text"
      },
      "source": [
        "### Lets generate some fake data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kyqaIyhmDMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise = torch.randn(len(ParticleMomentum_b), NOISE_DIM)\n",
        "ParticleMomentum_ParticlePoint = torch.cat([ParticleMomentum, \n",
        "                                            ParticlePoint], dim=1)\n",
        "EnergyDeposit_gen = generator_cpu(noise, ParticleMomentum_ParticlePoint_b.cpu())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s353zPylmDMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EnergyDeposit_gen = EnergyDeposit_gen.detach().cpu().numpy().reshape(-1, 30, 30)\n",
        "EnergyDeposit = EnergyDeposit.detach().cpu().numpy().reshape(-1, 30, 30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TD90ylsmDMd",
        "colab_type": "text"
      },
      "source": [
        "#### Plot one image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxhjGZGYmDMe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "6e9ba85a-08c8-418b-a7b7-ce3d031d1d76"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(EnergyDeposit_gen[0])\n",
        "plt.colorbar()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f133c4ea860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAEBCAYAAAD8avfTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTftFOhSmDMg",
        "colab_type": "text"
      },
      "source": [
        "## Calculate PRD score between these batch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWEusQu0mDMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Regressor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Regressor, self).__init__()\n",
        "        self.batchnorm0 = nn.BatchNorm2d(1)\n",
        "        self.conv1 = nn.Conv2d(1, 16, 2, stride=2)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 2, stride=2)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 2, stride=2)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 2)\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        \n",
        "        self.fc1 = nn.Linear(256, 256) \n",
        "        self.batchnorm4 = nn.BatchNorm1d(256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 2 + 3)\n",
        "        self.fc5 = nn.Linear(64, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.batchnorm0(self.dropout(x))\n",
        "        x = self.batchnorm1(self.dropout(F.relu(self.conv1(x))))\n",
        "        x = self.batchnorm2(F.relu(self.conv2(x)))\n",
        "        x = self.batchnorm3(F.relu(self.conv3(x)))\n",
        "        x = F.relu(self.conv4(x)) # 64, 5, 5\n",
        "        x = x.view(len(x), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.batchnorm4(self.dropout(F.relu(self.fc1(x))))\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        x = torch.tanh(self.fc3(x))\n",
        "        return self.fc4(x), self.fc5(x)\n",
        "    \n",
        "    def get_encoding(self, x):\n",
        "        x = self.batchnorm0(self.dropout(x))\n",
        "        x = self.batchnorm1(self.dropout(F.relu(self.conv1(x))))\n",
        "        x = self.batchnorm2(F.relu(self.conv2(x)))\n",
        "        x = self.batchnorm3(F.relu(self.conv3(x)))\n",
        "        x = F.relu(self.conv4(x)) # 64, 5, 5\n",
        "        x = x.view(len(x), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.batchnorm4(self.dropout(F.relu(self.fc1(x))))\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "    \n",
        "\n",
        "def load_embedder(path):\n",
        "    embedder = torch.load(path)\n",
        "    embedder.eval()\n",
        "    return embedder\n",
        "\n",
        "embedder = load_embedder('./embedder.tp')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd63IOwVmDMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_real = embedder.get_encoding(torch.tensor(EnergyDeposit).float().view(-1, 1, 30, 30)).detach().numpy()\n",
        "data_fake = embedder.get_encoding(torch.tensor(EnergyDeposit_gen).float().view(-1, 1, 30, 30)).detach().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGM2uI_qmDMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_pr_aucs(precisions, recalls):\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    pr_aucs = []\n",
        "    for i in range(len(recalls)):\n",
        "        plt.step(recalls[i], precisions[i], color='b', alpha=0.2,  label='PR-AUC={}'.format(auc(precisions[i], recalls[i])))\n",
        "        pr_aucs.append(auc(precisions[i], recalls[i]))\n",
        "    plt.step(np.mean(recalls, axis=0), np.mean(precisions, axis=0), color='r', alpha=1,  label='average')\n",
        "    plt.fill_between(np.mean(recalls, axis=0), \n",
        "                     np.mean(precisions, axis=0) - np.std(precisions, axis=0) * 3,\n",
        "                     np.mean(precisions, axis=0) + np.std(precisions, axis=0) * 3, color='g', alpha=0.2,  label='std')\n",
        "\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "\n",
        "    # plt.ylim([0.0, 1.05])\n",
        "    # plt.xlim([0.0, 1.0])\n",
        "    print(np.mean(pr_aucs), np.std(pr_aucs))\n",
        "    plt.legend()\n",
        "    \n",
        "    return pr_aucs\n",
        "\n",
        "def calc_pr_rec(data_real, data_fake, num_clusters=20, num_runs=10, NUM_RUNS=10):\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    for i in tqdm(range(NUM_RUNS)):\n",
        "        precision, recall = compute_prd_from_embedding(data_real, data_fake, num_clusters=num_clusters, num_runs=num_runs)\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "    return precisions, recalls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NApjdKVmDMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "precisions, recalls = calc_pr_rec(data_real, data_fake, num_clusters=100, num_runs=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0D4-j__mDMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_aucs = plot_pr_aucs(precisions, recalls)\n",
        "plt.title('Num_clusters={}, num_runs={}, first third'.format(100, 20))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erF_MpJ_mDMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_aucs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXkiQuGlmDMs",
        "colab_type": "text"
      },
      "source": [
        "## Physical metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI_33EaxmDMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.lines as mlines\n",
        "def newline(p1, p2):\n",
        "    ax = plt.gca()\n",
        "    xmin, xmax = ax.get_xbound()\n",
        "\n",
        "    if(p2[0] == p1[0]):\n",
        "        xmin = xmax = p1[0]\n",
        "        ymin, ymax = ax.get_ybound()\n",
        "    else:\n",
        "        ymax = p1[1]+(p2[1]-p1[1])/(p2[0]-p1[0])*(xmax-p1[0])\n",
        "        ymin = p1[1]+(p2[1]-p1[1])/(p2[0]-p1[0])*(xmin-p1[0])\n",
        "\n",
        "    l = mlines.Line2D([xmin,xmax], [ymin,ymax])\n",
        "    ax.add_line(l)\n",
        "    return l\n",
        "\n",
        "def plot_axes_for_shower(ecal, point, p):\n",
        "    x = np.linspace(-14.5, 14.5, 30)\n",
        "    y = np.linspace(-14.5, 14.5, 30)\n",
        "\n",
        "    xx, yy = np.meshgrid(x, y)\n",
        "    zoff = 25.\n",
        "    ipic = 3\n",
        "    orth = np.array([-p[1], p[0]])\n",
        "\n",
        "    pref = point[:2] + p[:2] * zoff / p[2]\n",
        "\n",
        "    p1 = pref - 10 * p[:2]\n",
        "    p2 = pref + 10 * p[:2]\n",
        "    p3 = pref - 10 * orth\n",
        "    p4 = pref + 10 * orth\n",
        "\n",
        "    plt.contourf(xx, yy, np.log(ecal + 1), cmap=plt.cm.inferno)\n",
        "    newline(p1, p2)\n",
        "    newline(p3, p4)\n",
        "    plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR08nJ9gmDMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = 2\n",
        "plot_axes_for_shower(EnergyDeposit[idx], point=ParticlePoint[idx].detach().numpy(),\n",
        "                     p=ParticleMomentum[idx].detach().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUCqH0_SmDMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from calogan_metrics import get_assymetry, get_shower_width, get_sparsity_level"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbvzfsYUmDM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assym = get_assymetry(EnergyDeposit, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy(), orthog=False)\n",
        "assym_ortho = get_assymetry(EnergyDeposit, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy(), orthog=True)\n",
        "sh_width = get_shower_width(EnergyDeposit, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy(), orthog=False)\n",
        "sh_width_ortho = get_shower_width(EnergyDeposit, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy(), orthog=True)\n",
        "sparsity_level = get_sparsity_level(EnergyDeposit)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eJLvn3EmDM2",
        "colab_type": "text"
      },
      "source": [
        "## Longitudual cluster asymmetry"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEORbnE7mDM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set(font_scale=2)\n",
        "plt.hist(assym, bins=50, range=[-1, 1], color='red', alpha=0.3, normed=True, label='MC');\n",
        "plt.xlabel('Longitudual cluster asymmetry')\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15wFghYcmDM3",
        "colab_type": "text"
      },
      "source": [
        "## Transverse cluster asymmetry"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfge5LTMmDM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set(font_scale=2)\n",
        "plt.hist(assym_ortho, bins=50, range=[-1, 1], color='red', alpha=0.3, normed=True, label='MC');\n",
        "plt.xlabel('Transverse cluster asymmetry')\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4lWh8VAmDM5",
        "colab_type": "text"
      },
      "source": [
        "## Cluster longitudual width"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB27rAtImDM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(sh_width, bins=50, range=[0, 15], normed=True, alpha=0.3, color='red', label='MC');\n",
        "plt.title('Shower longitudial width')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('Cluster longitudual width [cm]')\n",
        "plt.ylabel('Arbitrary units')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC-HiFBamDM7",
        "colab_type": "text"
      },
      "source": [
        "## Cluster trasverse width"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBIu8gwLmDM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(sh_width_ortho, bins=50, range=[0,10], normed=True, alpha=0.3, color='blue', label='MC');\n",
        "#plt.title('Shower transverse width')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('Cluster trasverse width [cm]')\n",
        "plt.ylabel('Arbitrary units')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pFbBYvOmDNA",
        "colab_type": "text"
      },
      "source": [
        "## Sparsity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob53fPO_mDNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alphas = np.log(np.logspace(-5, -1, 20))\n",
        "means_r = np.mean(sparsity_level, axis=1)\n",
        "stddev_r = np.std(sparsity_level, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QygKaRldmDNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(alphas, means_r, color='red')\n",
        "plt.fill_between(alphas, means_r-stddev_r, means_r+stddev_r, color='red', alpha=0.3)\n",
        "plt.legend(['MC'])\n",
        "plt.title('Sparsity')\n",
        "plt.xlabel('log10(Threshold/GeV)')\n",
        "plt.ylabel('Fraction of cells above threshold')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-imUBMEmDND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from calogan_metrics import get_physical_stats\n",
        "real_phys_stats = get_physical_stats(EnergyDeposit, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy())\n",
        "gen_phys_stats = get_physical_stats(EnergyDeposit_gen, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp_s9vGcmDNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "precisions, recalls = calc_pr_rec(real_phys_stats, gen_phys_stats, num_clusters=100, num_runs=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btvs99JKmDNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_aucs = plot_pr_aucs(precisions, recalls)\n",
        "plt.title('Num_clusters={}, num_runs={}, first third'.format(100, 20))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOyBgN-4mDNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_aucs"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}